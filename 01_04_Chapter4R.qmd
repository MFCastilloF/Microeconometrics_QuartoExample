---
title: "Chapter 4"
bibliography: references.bib
engine: knitr
---

```{r echo=FALSE}
knitr::opts_chunk$set(message = F, warning = F)
rm(list = ls())
```

# Tools required for Chapter 4

# Code Call-outs

## Code Call-out 4.1: Wild cluster bootstrap implementation

## Code call-out 4.2: Exploring the Two-way Fixed Effect Model and Parameter Decompositions

**Two-Way Fixed Effects Estimators and Heterogeneous Treatment Effects** To understand the potential issues related to heterogeneous treatment effects over time and two-way fixed effect estimators, we will examine a pair of numerical examples. In particular, we will focus on the composition of the two way FE estimator $\tau$ estimated from: $$
y_{st} = \gamma_s + \lambda_t + \tau w_{st} + \varepsilon_{st}
$$ {#eq-twfe} where $y_{st}$ is the outcome variable, $\gamma_s$ and $\lambda_t$ are state (unit) and time fixed effects, $w_{st}$ is the binary treatment variable that takes the value of 1 if a state (unit) $s$ is treated at time $t$ and otherwise takes 0. We will work with a quite tractable example based on three units and 10 time periods, and will document how the approaches taken by @GoodmanBacon2018 and by @deChaisemartinDhaultfoeuille2019 to understand the two-way FE estimator compare.

The results from @GoodmanBacon2018 and those from @deChaisemartinDhaultfoeuille2019 are similar, however they take quite different paths to get there. Goodman-Bacon's (like that laid out in @AtheyImbens2018) is "mechanical" in that it is based on the underlying difference-in-differences comparisons between all groups. The result in @deChaisemartinDhaultfoeuille2019 is based on a potential outcomes frame-work, and counterfactuals under parallel trend assumptions. Thus to examine how these methods work requires somewhat different frameworks. In the case of @GoodmanBacon2018, we should consider all possible DD comparisons, while in the case of @deChaisemartinDhaultfoeuille2019 we should consider the treatment effect for each unit and time period, which requires knowing the observed and counterfactual state. While the approaches the two papers take to understand the content of the estimator differ, they refer to the same estimator, so always recover the same parameter estimate. To examine this in a more applied way, we will look at a simulated example.

To do this, let's consider a panel of 3 states/areas over the 10 years ($t$) of 2000 to 2009. One of these units is entirely untreated ($unit = 1$ or group $U$), one is treated at an early time period, 2003, ($unit = 2$ or group $k$), and the other is treated at a later time period, 2006, ($unit = 3$ or group $l$). We will construct a general structure for this data below:

```{r}
Data <- data.frame(unit = ceiling(1:30/10), year = rep(2000:2009, 3))
head(Data)
```

We will consider a simple-case where the actual data-generating process is known as: $$y_{unit,t} = 2 + 0.2 \times (t - 2000) + 1 \times unit + \beta_1 \times post \times unit + \beta_2 \times post \times unit \times (t - treat).$$ Here $unit$ refers to the unit number listed above (1, 2 or 3), $post$ indicates that a unit is receiving treatment in the relevant time period $t$, and $treat$ refers to the treatment period (2003 for unit 2, and 2006 for unit 3). Let's generate treatment, time to treatment, and post-treatment variables in `R`:

```{r}
Data$treat <- ifelse(Data$unit == 2, 2006, ifelse(Data$unit == 3, 2003, 0))
Data$time  <- ifelse(Data$treat == 0, 0, Data$year - Data$treat)
Data$post  <- ifelse(Data$time >= 0 & Data$treat != 0, 1, 0)
```

This specification allows for each unit to have its own fixed effect, given that $unit$ is multiplied by 1, and allows for a general time trend increasing by 0.2 units each period across the whole sample. These parameters are not so important, as what we care about are the treatment effects themselves. The impact of treatment comes from the units $\beta_1$ and $\beta_2$. The first of these, $\beta_1$, captures an immediate unit-specific jump when treatment is implemented which remains stable over time. The second of these, $\beta_2$, implies a trend break occurring *only* for the treated units once treatment comes into place. We will consider 2 cases below. In the first case $\beta_1 = 1$ and $\beta_2 = 0$ (a simple case with a constant treatment effect per unit):

```{r}
Data$y1 <- 2 + (Data$year - 2000) * 0.2 + 1 * Data$unit + 1 * Data$post * Data$unit + 
  0 * Data$post * Data$unit * (Data$time)
```

and in a second case $\beta_1 = 1$ and $\beta_2 = 0.45$. This is a more complex case in which there are heterogeneous treatment effects over time:

```{r}
Data$y2 <- 2 + (Data$year - 2000) * 0.2 + 1 * Data$unit + 1 * Data$post * Data$unit +
  0.45 * Data$post * Data$unit * (Data$time)
```

These two cases are plotted next where the line with empty circles refers to group $U$, the line with black filled circles refers to group $k$ and the line with squares refers to group $l$

```{r fig.width=10}
#| code-fold: true
#| code-summary: "Show the plot code"
library(ggplot2)
library(ggpubr)
p1 <- ggplot(data = Data, aes(x = year, y = y1, color = as.factor(unit))) +
  geom_line(linetype = 1, size = 0.5) +
  geom_point(aes(shape = as.factor(unit)), size = 2) +
  scale_shape_manual(values = c(1, 16, 12)) +
  scale_color_manual(values = c("black", "black", "black")) +
  labs(x = "Time", y = "Outcome Variable") +
  scale_x_continuous(breaks = seq(from = 2000, to = 2009, by = 2)) +
  scale_y_continuous(breaks = seq(from = 0, to = 12, by = 2),
                     labels = seq(from = 0, to = 12, by = 2),
                     limits = c(0,12)) +
  geom_vline(xintercept = 2002, color = "red", linetype = 2) +
  geom_vline(xintercept = 2005, color = "red", linetype = 2) +
  theme(legend.position = "none")
t1 <- ggplot() + geom_text(aes(x = 0, y = 0, label = "(a) Simple Decomposition")) +
  theme_void()
p2 <- ggplot(data = Data, aes(x = year, y = y2, color = as.factor(unit))) +
  geom_line(linetype = 1, size = 0.5) +
  geom_point(aes(shape = as.factor(unit)), size = 2) +
  scale_shape_manual(values = c(1, 16, 12)) +
  scale_color_manual(values = c("black", "black", "black")) +
  labs(x = "Time", y = "Outcome Variable") +
  scale_x_continuous(breaks = seq(from = 2000, to = 2009, by = 2)) +
  scale_y_continuous(breaks = seq(from = 0, to = 20, by = 5),
                     labels = seq(from = 0, to = 20, by = 5),
                     limits = c(0,20)) +
  geom_vline(xintercept = 2002, color = "red", linetype = 2) +
  geom_vline(xintercept = 2005, color = "red", linetype = 2) +
  theme(legend.position = "none")
t2 <- ggplot() + geom_text(aes(x = 0, y = 0, label = "(b) Decomposition with trends")) +
  theme_void()
ggarrange(plotlist = list(p1, p2, t1, t2), ncol = 2, nrow = 2, heights = c(0.9, 0.1))
```


```{r echo=F}
rm(p1, p2, t1, t2)
```

### The Two-way Fixed Effect Estimator

First we will estimate the parameter by two-way fixed effects regression. This will provide us with the parameter estimate that both @GoodmanBacon2018 and @deChaisemartinDhaultfoeuille2019 will construct in a piece-wise fashion. This is done relatively simply in `R`. We simply estimate @eq-twfe by linear regression using `lm` as laid out below:

```{r}
case1 <- lm(data = Data,
            formula = y1 ~ factor(unit) + factor(year) + post)
paste0("The parameter estimates by two-way fixed effects regression for the ",
       "case 1 is: ", case1$coefficients["post"])
case2 <- lm(data = Data,
            formula = y2 ~ factor(unit) + factor(year) + post)
paste0("The parameter estimates by two-way fixed effects regression for the ",
       "case 2 is: ", case2$coefficients["post"])
```

Here we see that the coefficient of interest is 2.454545. We can see that this is between the two unit-specific jumps that occur with treatment (2 and 3). We will see below why it takes this particular weighted average.

### @GoodmanBacon2018 Decomposition

Using the values simulated above, let's see how the @GoodmanBacon2018 decomposition allows us to understand estimated treatment effects. We will consider both:\
- (a) Simple Decomposition\
- (b) Decomposition with trends

The methodology @GoodmanBacon2018 decomposition suggests that we should calculate all $2 \times 2$ combinations of states and time where post-treatment units are compared to "untreated" unit (laid out at more length in the boo). In this example, this provides four specific effects, which contribute to $\widehat{\tau}$ as a weighted mean. The specific effects desired are:

-   A. $\widehat{\beta}^{2\times2}_{kU}$ from the comparison of the early treated unit with the untreated unit.\
-   B. $\widehat{\beta}^{2\times2}_{lU}$, from the comparison of the latter treated unit with the untreated unit.\
-   C. $\widehat{\beta}^{2\times2,k}_{kl}$, from the comparison of the early and latter treated units, when the early unit begin to be treated.\
-   D. $\widehat{\beta}^{2\times2,l}_{kl}$, from the comparison of the early and latter treated units, when the latter unit begin to be treated.

These will then be weighted as laid out in @GoodmanBacon2018 to provide the regression-based estimate.

#### (a) Simple Decomposition

In this case the @GoodmanBacon2018 methodology estimate $\widehat{\tau}$ weighting the next four DD comparisons

```{r}
#| code-fold: true
#| code-summary: "Show the plot code"
library(dplyr)
p1 <- ggplot(data = Data, aes(x = year, y = y1, color = as.factor(unit))) +
  geom_line(linetype = 1, size = 0.5, aes(alpha = as.factor(unit))) +
  geom_point(aes(shape = as.factor(unit), alpha = as.factor(unit)), size = 2) +
  scale_alpha_manual(values = c(1,0.1,1)) +
  scale_shape_manual(values = c(1, 16, 12)) +
  scale_color_manual(values = c("black", "black", "black")) +
  labs(x = "Time", y = "Outcome Variable") +
  scale_x_continuous(breaks = seq(from = 2000, to = 2009, by = 2)) +
  scale_y_continuous(breaks = seq(from = 0, to = 12, by = 2),
                     labels = seq(from = 0, to = 12, by = 2),
                     limits = c(0,12)) +
  geom_vline(xintercept = 2002, color = "red", linetype = 2) +
  geom_vline(xintercept = 2005, color = "red", linetype = 2) +
  theme(legend.position = "none")
p2 <- ggplot(data = Data, aes(x = year, y = y1, color = as.factor(unit))) +
  geom_line(linetype = 1, size = 0.5, aes(alpha = as.factor(unit))) +
  geom_point(aes(shape = as.factor(unit), alpha = as.factor(unit)), size = 2) +
  scale_alpha_manual(values = c(1,1,0.1)) +
  scale_shape_manual(values = c(1, 16, 12)) +
  scale_color_manual(values = c("black", "black", "black")) +
  labs(x = "Time", y = "Outcome Variable") +
  scale_x_continuous(breaks = seq(from = 2000, to = 2009, by = 2)) +
  scale_y_continuous(breaks = seq(from = 0, to = 12, by = 2),
                     labels = seq(from = 0, to = 12, by = 2),
                     limits = c(0,12)) +
  geom_vline(xintercept = 2002, color = "red", linetype = 2) +
  geom_vline(xintercept = 2005, color = "red", linetype = 2) +
  theme(legend.position = "none")
p3 <- Data %>% filter(year < 2006) %>%
  ggplot(aes(x = year, y = y1, color = as.factor(unit))) +
  geom_line(linetype = 1, size = 0.5, aes(alpha = as.factor(unit))) +
  geom_point(aes(shape = as.factor(unit), alpha = as.factor(unit)), size = 2) +
  scale_alpha_manual(values = c(0.1,1,1)) +
  scale_shape_manual(values = c(1, 16, 12)) +
  scale_color_manual(values = c("black", "black", "black")) +
  labs(x = "Time", y = "Outcome Variable") +
  scale_x_continuous(breaks = seq(from = 2000, to = 2009, by = 2),
                     limits = c(2000,2009)) +
  scale_y_continuous(breaks = seq(from = 0, to = 12, by = 2),
                     labels = seq(from = 0, to = 12, by = 2),
                     limits = c(0,12)) +
  geom_vline(xintercept = 2002, color = "red", linetype = 2) +
  geom_vline(xintercept = 2005, color = "red", linetype = 2) +
  theme(legend.position = "none")
p4 <- Data %>% filter(year >= 2003) %>%
  ggplot(aes(x = year, y = y1, color = as.factor(unit))) +
  geom_line(linetype = 1, size = 0.5, aes(alpha = as.factor(unit))) +
  geom_point(aes(shape = as.factor(unit), alpha = as.factor(unit)), size = 2) +
  scale_alpha_manual(values = c(0.1,1,1)) +
  scale_shape_manual(values = c(1, 16, 12)) +
  scale_color_manual(values = c("black", "black", "black")) +
  labs(x = "Time", y = "Outcome Variable") +
  scale_x_continuous(breaks = seq(from = 2000, to = 2009, by = 2),
                     limits = c(2000,2009)) +
  scale_y_continuous(breaks = seq(from = 0, to = 12, by = 2),
                     labels = seq(from = 0, to = 12, by = 2),
                     limits = c(0,12)) +
  geom_vline(xintercept = 2002, color = "red", linetype = 2) +
  geom_vline(xintercept = 2005, color = "red", linetype = 2) +
  theme(legend.position = "none")
t1 <- ggplot() + 
  geom_text(aes(x = 0, y = 0, label = "A. Early Group v/s Untreated Group"), size = 3) +
  theme_void()
t2 <- ggplot() + 
  geom_text(aes(x = 0, y = 0, label = "B. Later Group v/s Untreated Group"), size = 3) +
  theme_void()
t3 <- ggplot() + 
  geom_text(aes(x = 0, y = 0, label = "C. Early Group v/s Later Group Before 2006"), 
            size = 3) +
  theme_void()
t4 <- ggplot() + 
  geom_text(aes(x = 0, y = 0, label = "D. Early Group v/s Later Group After 2003"), 
            size = 3) +
  theme_void()
ggarrange(plotlist = list(t1, t2, p1, p2, t3, t4, p3, p4), ncol = 2, nrow = 4, 
          heights = c(0.1, 0.4, 0.1, 0.4))
```

```{r echo=FALSE}
rm(p1, p2, p3, p4, t1, t2, t3, t4)
```

As seen in the plots, in the simple decomposition these effects are constants of 3 and 2 for early and later treated units given that the "treatment effect" is simply $1 \times unit$ in each case.

##### A. Early Group v/s Untreated Group

In order to calculate the effects we start making the simple DD comparison of the untreated group $U$ ($unit = 1$) with the early treated group $k$ ($unit = 3$) getting $\widehat{\beta}^{2 \times 2}_{kU}$ as $$\widehat{\beta}^{2 \times 2}_{kU} = \left( \overline{y}_k^{Post(k)} - \overline{y}_k^{Pre(k)} \right) - \left( \overline{y}_U^{Post(k)} - \overline{y}_U^{Pre(k)} \right)$$ Where $\overline{y}_k^{Post(k)}$ is the mean of the outcome variable for the early treated group $k$ ($unit = 3$) posterior to treatment, from 2003, $\overline{y}_k^{Pre(k)}$ is the mean for of the outcome variable for the early treated group $U$ ($unit = 3$) prior to treatment, (up until 2002), and $\overline{y}_U^{Post(k)}, \overline{y}_U^{Post(k)}$ are the analogous quantities for the untreated group $U$ ($unit = 1$)

```{r}
(mean(Data$y1[Data$unit == 3 & Data$post == 1]) -
   mean(Data$y1[Data$unit == 3 & Data$post == 0])) -
  (mean(Data$y1[Data$unit == 1 & Data$year >= 2003]) -
     mean(Data$y1[Data$unit == 1 & Data$year < 2003]))
```

This result also can be obtained from the linear regression with the canonical DD formula $$y_{unit,t} = \alpha_0 + \alpha_1 \times Post(k) + \alpha_2 \times \mathbf{1}(unit = 3) + \beta_{kU}^{2\times2} \times Post(k) \times \mathbf{1}(unit = 3) + \varepsilon_i$$ Where $Post(k)$ indicates that the year is equal or greater than the year where the group $k$ ($unit = 3$) received the treatment (2003) and $\mathbf{1}(unit = 3)$ indicates if the observation is from the early treated group $k$ ($unit = 3$)

```{r}
summary(lm(y1 ~ factor(year >= 2003) + factor(unit) + factor(year >= 2003):factor(unit), 
           data = Data, subset = (unit != 2)))
```

A third way to obtain this is from the next linear regression $$y_{unit,t} = \alpha_0 + \beta_{kU}^{2 \times 2} \times Post + \sum_{i = 2001}^{2009} \alpha_{i-2000} \times \mathbf{1}(year = i) + \alpha_{10} \times \mathbf{1}(unit = 3) + \varepsilon_i$$ Where in this case $Post$ indicates if the unit is treated (note for group $U$ this will be always 0), $\mathbf{1}(year = i)$ indicates if the observation is in period $i \in \{2001, \ldots, 2009\}$ and $\mathbf{1}(unit = 3)$ keep its meaning

```{r}
summary(lm(y1 ~ post + factor(year) + factor(unit), data = Data, subset = (unit != 2)))
```

Now we store this result for posterior use

```{r}
bku <- lm(y1 ~ post + factor(year) + factor(unit), data = Data,
          subset = (unit != 2))$coefficient["post"]
```

##### B. Later Group v/s Untreated Group

The next DD comparison we calculate is that which compares the later treated group $l$ ($unit = 2$) with the untreated group $U$ ($unit = 1$), resulting in $\widehat{\beta}^{2 \times 2}_{lU}$. As above, we can generate this DD estimate in a number of ways (most simply by double-differencing with means), and this will then be stored.

```{r}
blu <- lm(y1 ~ post + factor(year) + factor(unit), data = Data, 
   subset = (unit != 3))$coefficient["post"]
blu
(mean(Data$y1[Data$unit == 2 & Data$post == 1]) -
   mean(Data$y1[Data$unit == 2 & Data$post == 0])) -
  (mean(Data$y1[Data$unit == 1 & Data$year >= 2006]) -
     mean(Data$y1[Data$unit == 1 & Data$year < 2006]))
summary(lm(y1 ~ factor(year >= 2006) + factor(unit) + factor(year >= 2006):factor(unit), 
           data = Data, subset = (unit != 3)))
```

##### C. Early Group v/s Later Group Before 2006

Next we calculate the effects from the DD comparisons of early and later treated groups, up until the later treated group receives treatment (2006). This is: $$\widehat{\beta}^{2 \times 2, k}_{kl} \equiv \left( \overline{y}^{Mid(k,l)}_{k} - \overline{y}^{Pre(k)}_{k} \right) - \left( \overline{y}^{Mid(k,l)}_{l} - \overline{y}^{Pre(k)}_{l} \right)$$ where $\overline{y}^{Mid(k,l)}_{k}$ is the mean of the outcome variable for the early treated group $k$ ($unit = 3$) in the period between the treatment for the group $k$ and the group $l$ ($unit = 2$), from 2003 to 2005, $\overline{y}^{Pre(k)}_{k}$ is the mean for of the outcome variable for the early treated group $k$ ($unit = 3$) previous to treatment, until 2002, and $\overline{y}^{Mid(k,l)}_{l}, \overline{y}^{Pre(k)}_{l}$ are the analogous for the later treated group $l$ ($unit = 2$)

```{r}
bklk <- lm(y1 ~ post + factor(year) + factor(unit), data = Data,
   subset = (unit != 1 & year < 2006))$coefficient["post"]
bklk
(mean(Data$y1[Data$unit == 3 & (Data$year >= 2003 & Data$year < 2006)]) -
   mean(Data$y1[Data$unit == 3 & Data$year < 2003])) -
  (mean(Data$y1[Data$unit == 2 & (Data$year >= 2003 & Data$year < 2006)]) -
     mean(Data$y1[Data$unit == 2 & Data$year < 2003]))
summary(lm(y1 ~ factor(year >= 2003) + factor(unit) + factor(year >= 2003):factor(unit), 
           data = Data, subset = (unit != 1 & year < 2006)))
```

##### D. Early Group v/s Later Group After 2003

The last DD comparison is for early and later treated groups, starting from 2006 $$\widehat{\beta}^{2 \times 2, l}_{kl} \equiv \left( \overline{y}^{Post(l)}_{l} - \overline{y}^{Mid(k,l)}_{l} \right) - \left( \overline{y}^{Post(l)}_{k} - \overline{y}^{Mid(k,l)}_{k} \right)$$ Where $\overline{y}^{Post(l)}_{l}$ is the mean of the outcome variable for the later treated group $l$ ($unit = 2$) in the period after this group received the treatment, from 2006, $\overline{y}^{Mid(k,l)}_{l}$ is the mean for of the outcome variable for the later treated group $l$ ($unit = 2$) in the period between the treatment for the group $k$ ($unit = 3$) and the group $l$, from 2003 to 2005, and $\overline{y}^{Post(l)}_{k}, \overline{y}^{Mid(k,l)}_{k}$ are the analogous quantities for the early treated group $k$ ($unit = 3$). We can generate and save this quantity as we have previously:

```{r}
bkll <- lm(y1 ~ post + factor(year) + factor(unit), data = Data,
   subset = (unit != 1 & year > 2002))$coefficient["post"]
bkll
(mean(Data$y1[Data$unit == 2 & Data$year > 2005]) -
   mean(Data$y1[Data$unit == 2 & (Data$year >= 2003 & Data$year < 2006)])) -
  (mean(Data$y1[Data$unit == 3 & Data$year > 2005]) -
     mean(Data$y1[Data$unit == 3 & (Data$year >= 2003 & Data$year < 2006)]))
summary(lm(y1 ~ factor(year >= 2006) + factor(unit) + factor(year >= 2006):factor(unit==2), 
           data = Data, subset = (unit != 1 & year > 2002)))
```

This comparison is the comparison which can potentially result in undesired results if treatment effects are dynamic over time because it views group 3 (the previously treated group) as a control. However, in this case, given that treatment effects are homogenous over time we do not have a major problem here, and we observe that $\widehat{\beta}^{2 \times 2, l}_{kl}=2$.

##### Weights

We can now arrive to the OLS estimate of this two-way fixed effect model by generating the weighted mean of the previous estimates as: $$\widehat{\tau} = W_{kU} \cdot \widehat{\beta}^{2\times 2}_{kU} + W_{lU} \cdot \widehat{\beta}^{2\times 2}_{lU} + W_{kl}^{k} \cdot \widehat{\beta}^{2\times 2,k}_{kl} + W_{kl}^{l} \cdot \widehat{\beta}^{2\times 2,l}_{kl}$$ Where each $W$ is the weight that the respective $\beta$ has in this weighted mean, specifically: \begin{align*} 
W_{kU} & = \frac{(n_k + n_U)^2\widehat{V}^D_{kU}}{\widehat{V}^D} \quad &  \quad W_{lU} & = \frac{(n_l + n_U)^2\widehat{V}^D_{lU}}{\widehat{V}^D} \\ 
W_{kl}^k & = \frac{[(n_k + n_l)(1 - \overline{D}_l)]^2\widehat{V}^{D,k}_{kl}}{\widehat{V}^D} \quad &  \quad W_{kl}^l & = \frac{[(n_k + n_l)(1 - \overline{D}_k)]^2\widehat{V}^{D,l}_{kl}}{\widehat{V}^D}
\end{align*} Where $n$ refers to the sample share of the group

```{r}
nk = 1/3
nl = 1/3
nu = 1/3
```

$\overline{D}$ referes to the share of time the group is treated

```{r}
Dk = mean(Data$post[Data$unit==3])
Dl = mean(Data$post[Data$unit==2])
```

and $\widehat{V}$ refers to how much treatment varies

```{r}
VkU = 0.5*0.5*(Dk)*(1-Dk)
VlU = 0.5*0.5*(Dl)*(1-Dl) 
Vklk = 0.5*0.5*((Dk-Dl)/(1-Dl))*((1-Dk)/(1-Dl))
Vkll = 0.5*0.5*(Dl/Dk)*((Dk-Dl)/(Dk))
VD   = sum(lm(post ~ factor(unit) + factor(year), 
              data = Data)$residuals^2)/30
```

The weights are thus the following:

```{r}
wkU = ((nk + nu)^2*VkU)/VD
wkU
wlU = ((nl + nu)^2*VlU)/VD
wlU
wklk = (((nk + nl)*(1-Dl))^2*Vklk)/VD
wklk
wkll = (((nk + nl)*Dk)^2*Vkll)/VD
wkll
```

With this in mind the $\tau$ estimate is

```{r}
tau = wkU * bku + wlU * blu + wklk * bklk + wkll * bkll
tau
```

as observed in the two-way fixed effect estimate above.

#### (b) Decomposition with trends

In this case the @GoodmanBacon2018 decomposition follows as above generating the treatment effect as follows:

```{r}
#| code-fold: true
#| code-summary: "Show the plot code"
library(dplyr)
p1 <- ggplot(data = Data, aes(x = year, y = y2, color = as.factor(unit))) +
  geom_line(linetype = 1, size = 0.5, aes(alpha = as.factor(unit))) +
  geom_point(aes(shape = as.factor(unit), alpha = as.factor(unit)), size = 2) +
  scale_alpha_manual(values = c(1,0.1,1)) +
  scale_shape_manual(values = c(1, 16, 12)) +
  scale_color_manual(values = c("black", "black", "black")) +
  labs(x = "Time", y = "Outcome Variable") +
  scale_x_continuous(breaks = seq(from = 2000, to = 2009, by = 2)) +
  scale_y_continuous(breaks = seq(from = 0, to = 20, by = 5),
                     labels = seq(from = 0, to = 20, by = 5),
                     limits = c(0,20)) +
  geom_vline(xintercept = 2002, color = "red", linetype = 2) +
  geom_vline(xintercept = 2005, color = "red", linetype = 2) +
  theme(legend.position = "none")
p2 <- ggplot(data = Data, aes(x = year, y = y2, color = as.factor(unit))) +
  geom_line(linetype = 1, size = 0.5, aes(alpha = as.factor(unit))) +
  geom_point(aes(shape = as.factor(unit), alpha = as.factor(unit)), size = 2) +
  scale_alpha_manual(values = c(1,1,0.1)) +
  scale_shape_manual(values = c(1, 16, 12)) +
  scale_color_manual(values = c("black", "black", "black")) +
  labs(x = "Time", y = "Outcome Variable") +
  scale_x_continuous(breaks = seq(from = 2000, to = 2009, by = 2)) +
  scale_y_continuous(breaks = seq(from = 0, to = 20, by = 5),
                     labels = seq(from = 0, to = 20, by = 5),
                     limits = c(0,20)) +
  geom_vline(xintercept = 2002, color = "red", linetype = 2) +
  geom_vline(xintercept = 2005, color = "red", linetype = 2) +
  theme(legend.position = "none")
p3 <- Data %>% filter(year < 2006) %>%
  ggplot(aes(x = year, y = y2, color = as.factor(unit))) +
  geom_line(linetype = 1, size = 0.5, aes(alpha = as.factor(unit))) +
  geom_point(aes(shape = as.factor(unit), alpha = as.factor(unit)), size = 2) +
  scale_alpha_manual(values = c(0.1,1,1)) +
  scale_shape_manual(values = c(1, 16, 12)) +
  scale_color_manual(values = c("black", "black", "black")) +
  labs(x = "Time", y = "Outcome Variable") +
  scale_x_continuous(breaks = seq(from = 2000, to = 2009, by = 2),
                     limits = c(2000,2009)) +
  scale_y_continuous(breaks = seq(from = 0, to = 20, by = 5),
                     labels = seq(from = 0, to = 20, by = 5),
                     limits = c(0,20)) +
  geom_vline(xintercept = 2002, color = "red", linetype = 2) +
  geom_vline(xintercept = 2005, color = "red", linetype = 2) +
  theme(legend.position = "none")
p4 <- Data %>% filter(year >= 2003) %>%
  ggplot(aes(x = year, y = y2, color = as.factor(unit))) +
  geom_line(linetype = 1, size = 0.5, aes(alpha = as.factor(unit))) +
  geom_point(aes(shape = as.factor(unit), alpha = as.factor(unit)), size = 2) +
  scale_alpha_manual(values = c(0.1,1,1)) +
  scale_shape_manual(values = c(1, 16, 12)) +
  scale_color_manual(values = c("black", "black", "black")) +
  labs(x = "Time", y = "Outcome Variable") +
  scale_x_continuous(breaks = seq(from = 2000, to = 2009, by = 2),
                     limits = c(2000,2009)) +
  scale_y_continuous(breaks = seq(from = 0, to = 20, by = 5),
                     labels = seq(from = 0, to = 20, by = 5),
                     limits = c(0,20)) +
  geom_vline(xintercept = 2002, color = "red", linetype = 2) +
  geom_vline(xintercept = 2005, color = "red", linetype = 2) +
  theme(legend.position = "none")
t1 <- ggplot() + 
  geom_text(aes(x = 0, y = 0, label = "A. Early Group v/s Untreated Group"), size = 3) +
  theme_void()
t2 <- ggplot() + 
  geom_text(aes(x = 0, y = 0, label = "B. Later Group v/s Untreated Group"), size = 3) +
  theme_void()
t3 <- ggplot() + 
  geom_text(aes(x = 0, y = 0, label = "C. Early Group v/s Later Group Before 2006"), 
            size = 3) +
  theme_void()
t4 <- ggplot() + 
  geom_text(aes(x = 0, y = 0, label = "D. Early Group v/s Later Group After 2003"), 
            size = 3) +
  theme_void()
ggarrange(plotlist = list(t1, t2, p1, p2, t3, t4, p3, p4), ncol = 2, nrow = 4, 
          heights = c(0.1, 0.4, 0.1, 0.4))
```

```{r echo=FALSE}
rm(p1, p2, p3, p4, t1, t2, t3, t4)
```

As seen in the plots, in the decomposition with trends these effects are no longer constants of 3 and 2 for early and later treated units given that the "treatment effect" is no longer simply $1 \times unit$ in each case.

```{r}
# 2X2 DD Regressions
A <- lm(y2 ~ post + factor(year) + factor(unit), data = Data, subset=(unit!=2))
B <- lm(y2 ~ post + factor(year) + factor(unit), data = Data, subset=(unit!=3))
C <- lm(y2 ~ post + factor(year) + factor(unit), data = Data, subset=(unit!=1 & year<2006))
D <- lm(y2 ~ post + factor(year) + factor(unit), data = Data, subset=(unit!=1 & year>2002))
# 2x2 Betas
bkUk <- A$coefficient["post"]
bkUl <- B$coefficient["post"]
bklk <- C$coefficient["post"]
bkll <- D$coefficient["post"]
bkll
# Share of time treated
Dk = mean(Data$post[Data$unit==3])
Dl = mean(Data$post[Data$unit==2])
# How much treatment varies
VkUk = 0.5*0.5*(Dk)*(1-Dk)
VkUl = 0.5*0.5*(Dl)*(1-Dl) 
Vklk = 0.5*0.5*((Dk-Dl)/(1-Dl))*((1-Dk)/(1-Dl))
Vkll = 0.5*0.5*(Dl/Dk)*((Dk-Dl)/(Dk))
VD <- sum(lm(post ~ factor(unit) + factor(year), data = Data)$residuals^2/30)
# Share of sample
nk   = 1/3
nl   = 1/3
nu   = 1/3
# Weights
wkUk = ((nk + nu)^2*VkUk)/VD
wkUl = ((nl + nu)^2*VkUl)/VD
wklk = (((nk + nl)*(1-Dl))^2*Vklk)/VD
wkll = (((nk + nl)*Dk)^2*Vkll)/VD
# Tau
tau = bkUk*wkUk + bkUl*wkUl + bklk*wklk + bkll*wkll
tau
```

What is noteworthy here is the surprising behaviour flagged by @GoodmanBacon2018 for the final comparison based on the case where the earlier treated unit (unit 3) is used as a control for the later trated unit (unit 2). In this case, given that there *are* time-varying treatment effects, despite the fact that each unit-specific treatment effect is positive, we observe that the parameter $\widehat{\beta}^{2 \times 2, l}_{kl}$ is actually *negative*. In this particular example this negative value (-1.375) is not sufficient to turn the weighted treatment effect estimate negative, but if you play around with the size of the parameters $\beta_1$ and $\beta_2$ above, you will see that large enough differences in trends *can* result in such estimates! Here, as above, we see that when we aggregate unit-specific estimates as `tau`, the estimate (by definition) agrees with the estimate generated by two-way fixed effect models previously.

### @deChaisemartinDhaultfoeuille2019's Procedure
Now, we will show that the procedures described in @deChaisemartinDhaultfoeuille2019, despite arriving to the estimator in a different way, also let us understand how the regression weights the two-way fixed effect estimator.  In this case, rather than considering each treatment-control comparison pair, the authors note that the two-way fixed estimator can be conceived as a weighted sum of each single group by time period in any post-treatment group.

The authors define $\widehat{\beta}_{fe}$ as the coefficient estimated in the following (standard) two-way fixed effects regression: $$y_{i,s,t} = \beta_0 + \beta_{fe} D_{s,t} + \mu_s + \lambda_t + \varepsilon_{s,t}$$ Where $D_{s,t}$ is the mean over $i$ of a binary indicator variable that takes value of 1 if the unit $i$ in state $s$ is treated at period $t$ and 0 otherwise, in our case as we have one observartion per state $D_{s,t} = post_{s,t}$, meanwhile $\mu_s$ and $\lambda_t$ are state and time fixed effects. This is, of course, precisely the same model as we have estimated in @eq-twfe, implying that $\beta_{fe}=2.4545$ in cases without post-treatment trends (`y1`), or $\beta_{fe}=3.8045$ in cases with post-treatment dynamics (`y2`).

@deChaisemartinDhaultfoeuille2019 define the ATE for any ($s,t$) cell as: $$\Delta_{s,t} = \frac{1}{N_{s,t}} \sum_{i = 1}^{N_{s,t}}[Y_{i,s,t}(1) - Y_{i,s,t}(0)].$$  You will note that here we require an unobserved counterfactual $Y_{i,s,t}(0)$.  If we impose a parallel trend assumption, such a counterfactual can be inferred from unit-specific fixed effects, time-specific fixed effects, and the constant term.  Because in this case we *know* our data generating process, we can simply generate this counterfactual as the data generating process, absent any effect of treatment.  Below we generate such a counterfactual, where you will note that we impose that this is an 'untreated' counterfactual by setting the treatment effects to 0 in the generation of `y1_c` below:
```{r}
Data$y1_c <- 2 + (Data$year - 2000) * 0.2 + 1 * Data$unit + 0 * Data$post * Data$unit + 
  0 * Data$post * Data$unit * (Data$time)
```

It is likely useful to confirm to ourselves that graphically we are indeed generating the untreated counterfactual in this way.

```{r fig.width=10}
p1 <- ggplot(data = subset(Data, unit==2), aes(x = year)) +
      geom_line(aes(y = y1), color = "blue", size = 1.5) +
      geom_line(aes(y = y1_c), color = "red", linetype = "dashed", size = 1.5) +
      labs(x = "Year", y = "Y")
t1 <- ggplot() + geom_text(aes(x = 0, y = 0, label = "(a) Unit 2 Outcome and Counterfactual")) +
  theme_void()
p2 <- ggplot(data = subset(Data, unit==3), aes(x = year)) +
      geom_line(aes(y = y1), color = "blue", size = 1.5) +
      geom_line(aes(y = y1_c), color = "red", linetype = "dashed", size = 1.5) +
      labs(x = "Year", y = "Y")
t2 <- ggplot() + geom_text(aes(x = 0, y = 0, label = "(b) Unit 3 Outcome and Counterfactual")) +
  theme_void()
ggarrange(plotlist = list(p1, p2, t1, t2), ncol = 2, nrow = 2, heights = c(0.9, 0.1))
```

**NL** Podemos hacer lo siguiente aquí por favor?

- Agregar leyenda diciendo Y(1) para linea color azul, Y(0) para color rojo
- Arreglar bien las etiquetas de años como arriba (2000, 2002, ..., 2008)

This allows us to calculate a state- and time-period specific treatment effect ($\Delta_{s,t}$) for each treated unit.  We do so, calculating this quantity for all units in which treatment exists:

```{r}
Data$Delta_st[Data$post == 1] = Data$y1[Data$post == 1] - Data$y1_c[Data$post == 1]
print(Data[Data$post==1, c("y1", "y1_c", "unit", "year", "Delta_st")])
```

Unsurprisingly, given the data generating process we have defined, we see that each treatment effect is 2 for unit 2, and 3 for unit 3. If we were to calculate a mean treatment effect by hand, we may wish to simply take an average over all periods and units.  However, one of the key results of @deChaisemartinDhaultfoeuille2019 is to show that under a series of standard assumptions $$\beta_{fe} = E \left[ \sum_{s,t:D_{s,t}=1}\frac{N_{s,t}}{N_1}w_{s,t}\Delta_{s,t} \right]$$ Where $N_1$ refers to the sum of all treated observations and $$w_{s,t} = \frac{\varepsilon_{s,t}}{\sum_{s,t:D_{s,t}=1}\frac{N_{s,t}}{N_1}\varepsilon_{s,t}}$$ Where $\varepsilon_{s,t}$ is the residual from a regression of $D_{s,t}$ on state and time fixed-effects.  To confirm this in our data, we will estimate these regression residuals and add them into the dataframe:

```{r}
auxreg <- lm(post ~ factor(unit) + factor(year), data = Data)
Data$eps_st = auxreg$residuals
Data$eps_st[Data$post != 1] = NA
Data$w_st = Data$eps_st / sum(Data$eps_st, na.rm = T)
print(round(Data[Data$post==1, c("y1", "y1_c", "unit", "year", "Delta_st","w_st")],digits=15))
```
Note here that after generating $w_{s,t}$ we print this out using the round function to avoid very small digits appearing which are only different to zero given machine precision.  The key thing that we can see is that the effective weighting of treatment effects which occurs in regression is quite different to what we would expect.  Indeed, four periods are given 0 weights!  Finally, we can confirm that this decomposition gives us the two-way fixed effect estimate by multiplying $\Delta_{s,t}$ and $w_{s,t}$ and summing:


```{r}
print(paste0("de Chaisemartin and Xavier D'Haultfoeuille's decomposition ",
             "returns an estimates of: ", 
             sum(Data$Delta_st*Data$w_st, na.rm = T)))
```
We can see that correctly, this decomposition also returns the two-way fixed effect estimate of 2.4545.


We can follow precisely the same series of steps to see the case of the decomposition where treatment exposition also results in a trend-break.  To see this, we conduct each of the above steps below, however here we have not produced similar graphs (though you may wish to do so to confirm that counterfactuals make sense):

```{r}
Data$y2_c <- 2 + (Data$year - 2000) * 0.2 + 1 * Data$unit + 0 * Data$post * Data$unit + 
  0 * Data$post * Data$unit * (Data$time)
Data$Delta_st2[Data$post == 1] = Data$y2[Data$post == 1] - Data$y2_c[Data$post == 1]
print(round(Data[Data$post==1, c("y2", "y2_c", "unit", "year", "Delta_st2","w_st")],digits=15))
```

Because there is no difference in the structure of the treatment indicator or the unit and time fixed effects, the residuals $w_{s,t}$ are identical, though of course the treatment effects themselves, $\Delta_{s,t}$ are not.  Thus, once again we see that later treatment effects for unit 3 (precisely those units for which treatment effects are largest), are given zero weights.  Finally, again we can calculate the two-way fixed effect estimate following this decomposition by summing across units, capturing the estimate we have previously observed in regression models of 3.804545.  

```{r}
print(paste0("de Chaisemartin and Xavier D'Haultfoeuille's decomposition ",
             "returns an estimates of: ", 
             sum(Data$Delta_st2*Data$w_st, na.rm = T)))
```

Depending on the nature of treatment assignment, ie the number of treated periods, as well as the period in which treatment is adopted in different units, these weights will vary, and can even be negative.  You may wish to explore alternative set-ups and confirm to yourself that this is the case, and see that regardless of the nature of the setting, both @GoodmanBacon2018 and @deChaisemartinDhaultfoeuille2019's decompositions recover the two-way fixed effect estimate.

## Code call-out 4.3: Event study and Interaction-weighted Estimators


## Code call-out 4.4: Synthetic control, difference-in-differences, and synthetic difference-in-differences

The synthetic control method seeks to construct a "synthetic control" for a treated unit (in this case, California) using a weighted combination of control units (other states). The aim is for this synthetic control to closely resemble the treated unit in the pre-treatment period based on predictor variables.

- Use the 'synth' command to construct the synthetic control for California
- Predictor variables: cigsale from specific years, beer, lnincome, retprice, age15to24
- Treated unit: California (state==3)
- Treatment period: 1989
- Periods used to construct the synthetic control: 1980-1988

Once the synthetic control is constructed, we can compare the trends of the treated unit and the synthetic control in the post-treatment period. Any divergence in trends is interpreted as the treatment effect. In this case, we are assessing the impact of a hypothetical policy implemented in California in 1989 on cigarette sales.
```{r}
library(Synth)
library(haven)


california_data_url <- "Datasets/Abadie_data.csv"

california_dataframe <- read.csv(california_data_url)

dataprep_out <- dataprep(
  foo = california_dataframe,
  predictors = c("lnincome", "age15to24", "beer", "retprice"),
  special.predictors = list(
    list("cigsale", 1975, c("mean")),
    list("cigsale", 1980, c("mean")),
    list("cigsale", 1988, c("mean"))
  ),
  dependent = "cigsale",
  unit.variable = "state",
  time.variable = "year",
  treatment.identifier = "California",
  controls.identifier = unique(california_dataframe$state_name[-which(california_dataframe$state_name == "California")]),
  time.predictors.prior = 1970:1988,
  time.optimize.ssr = 1970:1988,
  time.plot = 1970:2000,
  unit.names.variable = "state_name"
) 


synth_out <- synth(
  data.prep.obj = dataprep_out
)


library(ggplot2)

# Synthetic California
synth_california <- dataprep_out$Y0 %*% synth_out$solution.w

# Data frame for plotting
plot_data <- data.frame(
  Year = 1970:2000,
  Cigsale = c(synth_california, dataprep_out$Y1),
  Type = rep(c("Synthetic California", "California"), each = 31)
)


line_types <- c("California" = "solid", "Synthetic California" = "dashed")
line_colors <- c("California" = "blue", "Synthetic California" = "red")
line_size <- 0.72  # Adjust this value as needed for line thickness

# Synthetic Control Plot
p <- ggplot(data = plot_data, aes(x = Year, y = Cigsale, color = Type, linetype = Type)) +
  geom_line(size = line_size) +  # Set line thickness
  geom_vline(xintercept = 1989, linetype = "dashed", color = "black", size = 0.7) +  # Same size for consistency
  labs(title = "Cigarette Sales in California vs. Synthetic Control",
       subtitle = "Tobacco Policy Change (1989)",
       x = "Year",
       y = "Cigarette Sales") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5),
        legend.title = element_blank(),
        legend.position = "bottom",
        legend.box.background = element_rect(color = "white", linewidth = 0.5),
        axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)),
        legend.text = element_text(size = 8)) +
  scale_color_manual(values = line_colors) +  # Set line colors
  scale_linetype_manual(values = line_types)  # Set line types

p
#ggsave("C:\\Users\\maria\\Desktop\\RA Microeconometría\\Cap4\\Abadie\\synthetic_control_plot.jpg", plot = p, width = 7, height = 5, dpi = 300)
```
**Results:**

- The synthetic control for California is constructed using a combination of other states. Specifically, weights are assigned to states like Colorado, Connecticut, Montana, Nevada, New Mexico, and Utah.
- The RMSPE (Root Mean Squared Prediction Error) is a measure of how well the synthetic control approximates California in the pre-treatment period. A lower RMSPE indicates a better fit. In this case, the RMSPE is 1.756235, suggesting a reasonably good fit.
- The "Predictor Balance" table shows how California and the synthetic control compare in terms of the predictor variables. The figures show that there is a good balance between the treated unit and the synthetic control on these variables.
- The graph displays per capita cigarette sales in California and the synthetic control over time. The divergence between the two lines post-1989 represents the estimated effect of the policy