---
title: "Chapter 2"
bibliography: refs.bib
engine: knitr
---

# Tools Required for Chapter 2

## An Introduction to Functions

### **Introduction to Functions in R**

Functions in R are essential for efficient and organized programming. They allow you to encapsulate code for specific tasks, making your scripts more modular, reusable, and easier to understand and debug.

### **Creating a Simple Function**

A simple function in R typically includes a name, arguments (inputs), a body (code that performs the operation), and a return value (the output). Here's an example of a basic function that adds two numbers:

```{r}

addNumbers <- function(a, b) {
  sum <- (a + b)
  return(sum)
}
addNumbers(10,5)

```

### **Understanding Function Arguments**

Arguments are placeholders for the data you pass to the function. They can be mandatory or optional, with optional arguments having default values:

```{r}

multiplyNumbers <- function(a, b = 2) {
  return(a * b)
}
multiplyNumbers(10)
```

### **Variable Scope and Return Value**

Variables defined inside a function are local to that function. The **`return()`** function specifies the output of your function. If **`return()`** is not explicitly called, R will return the last evaluated expression.

### **Advanced Functions with Arguments**

Functions with arguments are particularly useful in data analysis, as they can be applied to various datasets or variables.

**Example: Linear Regression Analysis Functions**

We will create two functions for linear regression analysis:

1.  **Perform Linear Regression**: This function performs a linear regression analysis and returns the model summary.

    ```{r}

    perform_linear_regression <- function(data, independent_var, dependent_var) {
      formula <- as.formula(paste(dependent_var, "~", independent_var))
      model <- lm(formula, data = data)
      return(summary(model))
    }

    ```

2.  **Print Regression Results**: This function prints the key results from the linear regression summary.

    ```{r}
    print_regression_results <- function(model_summary, description) {
      cat("Results for", description, ":\n")
      print(model_summary$coefficients)
      cat("R-squared:", model_summary$r.squared, "\n")
      cat("P-value:", pf(model_summary$fstatistic[1],
                         model_summary$fstatistic[2],
                         model_summary$fstatistic[3],
                         lower.tail = FALSE), "\n")
    }

    ```

### **Simulating Data for Demonstration**

To demonstrate the linear regression functions, let's create some simulated data:

```{r}
set.seed(1213)
data <- data.frame(
  marketing_spend = runif(100, 1, 1000),
  sales = rnorm(100, 500, 50)
)

```

### **Using the Linear Regression Functions**

Apply the functions to the simulated data:

```{r}
# Perform Linear Regression
regression_results <- perform_linear_regression(data, "marketing_spend", "sales")

# Print Regression Results
print_regression_results(regression_results, "Sales vs Marketing Spend")
```

## Simulation and Regression

To start, we will simulate some data based on the following data generating process:

$y_i = \beta_0 + \beta_1 x_i + \varepsilon_i$

where $\beta_0=1$, $\beta_1=2$, and both $x_i$ and $\varepsilon_i$ are distributed $\mathcal{N}(0,1)$. Having conducted this simulation, we will estimate a regression model to estimate $\widehat\beta_1$. In the book, you will be asked to consider examples which are more appropriate for the treatment effects framework which we are considering.

```{r}
set.seed(1213)
N <- 1000
x <- matrix(rnorm(N), N, 1)  # 1000 observations of a single independent variable
y <- 1 + 2 * x + matrix(rnorm(N), N, 1)  # Linear relationship with some noise

data <- data.frame(x = x, y = y)

# Linear Regression
model <- lm(y ~ x, data = data)

# Coefficients
beta1hat <- coef(model)["x"]
beta0hat <- coef(model)["(Intercept)"]

print(paste("beta 1 (Coefficient):", beta1hat))
print(paste("Intercept:", beta0hat))

# Predictions
data$yhat <- predict(model, newdata = data)

# Plot
par(mar = c(4, 4, 0.3, 0.3))
plot(data$x, data$y, xlab = expression(x), ylab = expression(y),
    pch = 19, col = 'blue')
abline(model, col = 'red', lwd = 2)
legend("topleft", legend = c("Data Points", "Regression Line"), 
       col = c("blue", "red"), pch = c(19, NA), lty = c(NA, 1))
```

Finally, we will do this 500 times, to see what the distribution of estimated paramters $\widehat\beta_1$ looks like:

```{r}
set.seed(1213)
beta1hats <- numeric(500)

for (i in 1:500) {
  x <- matrix(rnorm(N), N, 1)
  y <- 1 + 2 * x + matrix(rnorm(N), N, 1)
  data <- data.frame(x = x, y = y)
  model <- lm(y ~ x, data = data)
  beta1hats[i] <- coef(model)["x"]
}

# Mean estimate
mean_beta1hat <- mean(beta1hats)
print(paste('Mean coefficient estimate is:', mean_beta1hat))

# Histogram
par(mar = c(4, 4, 0.3, 0.3))
hist(beta1hats, breaks = 30, col = 'lightblue', border = 'black', main='',
     xlab = expression(hat(beta)[1]), ylab = "Frequency")
abline(v = 2, col = "red", lwd = 2, lty = 2)
legend("topright", legend = c(expression(beta[1]), "Estimates"), 
       col = c("red", "lightblue"), lty = c(2, NA), lwd = c(2, NA))

```

# Code Call Outs

## Code Call Out 2.1: Regression versus comparison of means

To understand the equivalence between regression analysis and the comparison of means in a binary regression set-up, we refer to Section 2.1 of the online coding resource. In this section, we work with data from a randomized control trial that examines asset transfers to poor households in India, as discussed in the paper by @Banerjeeetal2021.

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(readxl)
library(plyr)
library(ggplot2)
library(xtable)
library(tidyr)
library(haven)

# Load the household data
data <- read.csv("Datasets/Banerjee_et_al_2021.csv")

# Simple Regression for ind_fin_el1
fit <- lm(ind_fin_el1 ~ treatment, data = subset(data, el1 == 1))
summary(fit)  # Note down the coefficient for the treatment variable
coef_fit <- coef(fit)["treatment"]  # Extract the coefficient for the treatment variable

# Display the regression coefficient
cat("Coefficient for treatment in regression:", coef_fit, "\n")

# Calculate mean for the treatment group
mean_treatment <- mean(subset(data, treatment == 1 & el1 == 1)$ind_fin_el1, na.rm = TRUE)

# Calculate mean for the control group
mean_control <- mean(subset(data, treatment == 0 & el1 == 1)$ind_fin_el1, na.rm = TRUE)

# Calculate and display the difference in means
diff_means <- mean_treatment - mean_control
cat("Difference in means (Treatment - Control):", diff_means, "\n")

# Display the comparison
cat("The coefficient from the regression should be equal to the difference in means to demonstrate equivalence.\n")
```

## Code Call Out 2.2: Randomisation Inference

Randomization inference is perhaps best-illustrated with practical examples. A particularly illuminating approach to understand how randomisation inference works is visualization through tabular permutation. The following online coding resource provides a detailed introduction to this method. In this context, we will first consider a made-up example based on 3 treated units and 3 control units, before working with a larger number of control and treated units in data from the study "Long-Term effects of the Targeting the Ultra Poor Program" conducted by Abhijit Banerjee, Esther Duflo, and Garima Sharma.

### An Exact p-value

It is perhaps useful to see a simple example. Consider the case of 6 units, with 3 observations randomly assigned treatment. Imagine that the observed outcomes were then, in the treatment group: $(34,27,29)$, and in the control group: $(14,18,24)$. A simple comparison of means estimator suggests that the treatment effect is 11.33. To calculate a p-value, we can permute all the possible combinations, and ask what proportion of these are greater than or equal to this treatment effect. If we consider random orderings of 6 units, this suggests that there are $6!$ possible combinations, but in reality, as we are randomly choosing 3 units from these 6 to assign a permuted treatment status, the actual value of different combinations is $6\choose 3$ $=\frac{6!}{3!*(6-3)!}=20$. We document each of these possible permutations, as well as their permuted treatment effect in the Table below. In this case, we can see that only 1 of the 20 different permutations is greater than or equal to 11.33 he original treatment status). Suggesting an exact p-value of $1/20=0.05$.

| Permutation  | T1  | T2  | T3  | C1  | C2  | C3  | Estimate |
|--------------|-----|-----|-----|-----|-----|-----|----------|
| Original (1) | 34  | 27  | 29  | 14  | 18  | 24  | 11.33    |
| 2            | 34  | 27  | 14  | 29  | 18  | 24  | 1.33     |
| 3            | 34  | 27  | 18  | 14  | 29  | 24  | 4        |
| 4            | 34  | 27  | 24  | 14  | 18  | 29  | 8        |
| 5            | 34  | 14  | 29  | 27  | 18  | 24  | 2.67     |
| 6            | 34  | 18  | 29  | 14  | 27  | 24  | 5.33     |
| 7            | 34  | 24  | 29  | 14  | 18  | 27  | 9.33     |
| 8            | 14  | 27  | 29  | 34  | 18  | 24  | -2       |
| 9            | 18  | 27  | 29  | 14  | 34  | 24  | 0.67     |
| 10           | 24  | 27  | 29  | 14  | 18  | 34  | 4.67     |
| 11           | 34  | 14  | 18  | 27  | 29  | 24  | -4.67    |
| 12           | 34  | 14  | 24  | 27  | 18  | 29  | -0.67    |
| 13           | 34  | 18  | 24  | 14  | 27  | 29  | 2        |
| 14           | 14  | 27  | 18  | 34  | 29  | 24  | -9.33    |
| 15           | 14  | 27  | 24  | 34  | 18  | 29  | -5.33    |
| 16           | 18  | 27  | 24  | 14  | 34  | 29  | -2.67    |
| 17           | 14  | 18  | 29  | 34  | 27  | 24  | -8       |
| 18           | 14  | 24  | 29  | 34  | 18  | 27  | -4       |
| 19           | 18  | 24  | 29  | 14  | 34  | 27  | -1.33    |
| 20           | 14  | 18  | 24  | 34  | 27  | 29  | -11.33   |

: A Simple Illustration of Randomization Inference {.striped .hover .borderless .secondary}

```{r}
# Load required libraries
library(gtools)
library(ggplot2)

# Enter data
Y <- c(34, 27, 29, 14, 18, 24)
W <- c(1, 1, 1, 0, 0, 0)
data <- data.frame(Y, W)

# Calculate Difference in means estimator
tau <- mean(data$Y[data$W == 1]) - mean(data$Y[data$W == 0])

# Generate permutations of W
Wperm <- permutations(n = 6, r = 6, v = c(1,1,1,0,0,0), set = FALSE, repeats.allowed = FALSE)

# Calculate permuted treatment effects
Taus <- apply(Wperm, 1, function(p) {
  dataP <- data.frame(Y, W = p)
  mean(dataP$Y[dataP$W == 1]) - mean(dataP$Y[dataP$W == 0])
})

# Calculate p-values
p_2side <- sum(abs(Taus) >= tau) / length(Taus)
p_1side <- sum(Taus >= tau) / length(Taus)

cat("The two-sided p-value is:", p_2side, "\n")
cat("The one-sided p-value is:", p_1side, "\n")

# Generate graph
ggplot(data.frame(Taus), aes(x = Taus)) +
  geom_histogram(bins = 10, color = "black", fill = "lightblue", aes(y = ..density..)) +
  geom_vline(xintercept = tau, color = "red", linetype = "dashed") +
  labs(x = "Test statistic", y = "Density") +
  theme_minimal() +
  ggtitle("Permutation Inference")

```

### A Real world example

@Banerjeeetal2021

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(readxl)
library(plyr)
library(ggplot2)
library(xtable)
library(tidyr)
library(haven)

data <- read.csv("Datasets/Banerjee_et_al_2021.csv")

########Financial Index###########
# Observed treatment effect
obs_effect <- mean(data$ind_fin_el1[data$treatment == 1], na.rm = TRUE) - mean(data$ind_fin_el1[data$treatment == 0], na.rm = TRUE)
# Randomization inference
n_permutations <- 10000
permuted_effects <- numeric(n_permutations)
for (i in 1:n_permutations) {
  permuted_treatment <- sample(data$treatment)
  permuted_effect <- mean(data$ind_fin_el1[permuted_treatment == 1], na.rm = TRUE) - mean(data$ind_fin_el1[permuted_treatment == 0], na.rm = TRUE)
  permuted_effects[i] <- permuted_effect
}
# Calculate p-value
p_value <- mean(abs(permuted_effects) >= abs(obs_effect))
list(observed_effect = obs_effect, p_value = p_value)

########Asset Index###########
# Observed treatment effect
obs_effect <- mean(data$asset_ind_tot_el1[data$treatment == 1], na.rm = TRUE) - mean(data$asset_ind_tot_el1[data$treatment == 0], na.rm = TRUE)
# Randomization inference
n_permutations <- 10000
permuted_effects <- numeric(n_permutations)
for (i in 1:n_permutations) {
  permuted_treatment <- sample(data$treatment)
  permuted_effect <- mean(data$asset_ind_tot_el1[permuted_treatment == 1], na.rm = TRUE) - mean(data$asset_ind_tot_el1[permuted_treatment == 0], na.rm = TRUE)
  permuted_effects[i] <- permuted_effect
}
# Calculate p-value
p_value <- mean(abs(permuted_effects) >= abs(obs_effect))
list(observed_effect = obs_effect, p_value = p_value)
```

## Code Call Out 2.3: Bootstrap

For an introduction to the bootstrap, refer to Section 2.4.4 of the book. Here we will examine a computational implementation of a bootstrap standard error and confidence intervals, using data from @Banerjeeetal2021 which we have worked with above. First we will consider the main regression in Code Call-Out 2.1 $$Y_i = \mu + \tau_{ATE}W_i + \varepsilon_i.$$ Here we will work with the data we have loaded previously as data, and the condition `el1==1` which are those observations from the first endline survey, and examine the asset index (`asset_ind_tot_el1`) as our outcome measure $Y_i$. We can load the data and examine the estimated treatment effect via regression below.

```{r}
data <- read.csv("Datasets/Banerjee_et_al_2021.csv")
data <- data[data$el==1,]
fit <- lm(asset_ind_tot_el1 ~ treatment, data = data)
summary(fit)
```

From the summary we can note that $\widehat{\tau}_{ATE} = 0.408$ and its standard error equals 0.117. This suggests a p-value of 0.0005, and 95% confidence intervals of \[0.177;0.638\]. In this case the standard errors are computed via the standard OLS variance estimator, assuming homoscedastic errors, although heteroscedasticity-robust standard errors can be requested quite simply using the coeftest function from the `lmtest` library. This is loaded below, resulting in slight variations to the reported standard error (and correspondingly, p-value and resulting confidence intervals).

```{r}
library(lmtest)
library(sandwich)
coeftest(fit, vcov = vcovHC(fit, type = 'HC0'))
```

An alternative to these closed-form methods for variance estimation is to use bootstrap resampling methods. There are multiple ways a bootstrap can be implemented, but the simplest here will be to simply conduct a paired bootstrap, which is also robust to heteroscedasticity. The pairs bootstrap consists of, first, sampling with replacement the ordered pairs $\left\{(y_i,w_i)\right\}_{i=1}^{N} = \left\{(y_1,w_1),\ldots,(y_N,w_N)\right\}$ from original data, obtaining a "new" dataset of $N$ resampled pairs $\left\{(y_i^*,w_i^*)\right\}_{i=1}^{N} = \left\{(y_1^*,w_1^*),\ldots,(y_N^*,w_N^*)\right\}$. The new dataset thus simply consists of (potentially repeated) randomly selected rows of the original data. Let's see what this looks like with a single bootstrap replicate. First, we will generate a vector of size $N$, drawn with replacement. We do this below, having a look at the first 10 rows of the vector.

```{r}
set.seed(121316)
rows <- sample(1:nrow(fit$model), replace = T)
rows[1:10]
```

We see then, that the first row of our resampled data will consist of observation 96, the second row of observation 127, and so forth. Based on this vector, we can then build our new bootstrap resample, which will consist of the same number of observations as those in the original sample. Below we generate the resample, and have a look at the first few lines, confirming that they do effectively come from the observations indicated in our resampling vector.

```{r}
resampled <- data[rows,]
nrow(resampled)
head(resampled)
```

With this bootstrap sample we estimate again the coefficient of interest with standard OLS procedure:

```{r}
artificialModel <- lm(formula = asset_ind_tot_el1 ~ treatment,
                      data = resampled)
summary(artificialModel)
```

With this sample, we have obtained an estimate of $\widehat{\tau}_{ATE}^* = 0.569$; a different value to the original value, in line with variation in the sample used for estimation. If we want some idea of how much estimates vary as the sample changes (ie the sampling variation of our estimate), the next step simply consists of repeating this bootstrap process $B$ times, resulting in $B$ estimates of $\widehat{\tau}_{ATE,(b)}^*$ with $b\in\{1,\ldots,B\}$. Let's set $B=1,000$, and do this:

```{r}
B <- 1000
taus <- numeric(B)
for (i in 1:B) {
  rows <- sample(1:nrow(data), replace = T)
  resampled <- data[rows,]
  artificialModel <- lm(formula = asset_ind_tot_el1 ~ treatment,
                      data = resampled)
  taus[i] <- artificialModel$coefficients["treatment"]
}
```

You may wish to step through each of the lines in this loop to ensure that you can see what is going on, but the end product of this code is a vector called `taus` which has been filled in with $B$ estimates of $\tau$, $\left\{\widehat{\tau}^{(b)}\right\}_{b=1}^{B}$. We can have a look at the entire empirical distribution of these estimates as follows:

```{r}
ggplot() + geom_density(aes(x = taus)) +
  labs(title = latex2exp::TeX(input = "$\\widehat{\\tau}$ Empirical Distribution"),
       x = latex2exp::TeX(input = "$\\widehat{\\tau}$"),
       y = "Density") +
  geom_vline(xintercept = c(quantile(taus, 0.025), quantile(taus, 0.975)),
             color = 'red', linetype = 'dashed', linewidth = 1) +
  geom_vline(xintercept = 0.407753, color = 'grey', linewidth=2)
```

As we can see, this empirical distribution is close to centred on the original estimate (in the limit, they will be exactly the same, which is something you may wish to confirm by using a larger value for $B$), while also giving us some idea of the variation of the estimate over alternative resamples. We additionally plot the empirical 2.5^th^ and 97.5^th^ quantiles of the distribution, which provides a 95% confidence interval for $\widehat\tau$. Clearly, and in line with the regression results observed above, we can reject the null that $\tau=0$ with some certainty. Using these values $\left\{\widehat{\tau}^{(b)}\right\}_{b=1}^{B}$, finally we display the estimate's standard error as the standard deviation of the bootstrap estimates, and the confidence intervals can be generated from empirical quantiles. <!-- Similarly, if we wish to calculate a p-value, we can do so, asking how many values of the empirical distribution are more extreme than the estimate of interest.    --> We illustrate this below:

```{r, echo=2:9}
B<-1000
var_tau <- var(taus)
print(paste0("The variance estimate is: ", round(var_tau, 4), 
             " as such, the standard error estimates is: ", 
             round(sqrt(var_tau), 4)))
lower <- quantile(taus, 0.025)
upper <- quantile(taus, 0.975)
print(paste0("The empirical 95% confidence interval is: [",
             round(lower, 3), ",", round(upper,3), "]."))
```

We can see that the standard error, and hence 95% confidence interval, is very closely alligned to that from regression documented above, given both are valid under broadly similar assumptions.
