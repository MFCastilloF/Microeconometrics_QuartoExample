[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Microeconometrics: Methods and Applications",
    "section": "",
    "text": "Introduction\nSome info about the context."
  },
  {
    "objectID": "00_01_About.html",
    "href": "00_01_About.html",
    "title": "About this book",
    "section": "",
    "text": "Some info about the book."
  },
  {
    "objectID": "00_02_Download.html",
    "href": "00_02_Download.html",
    "title": "How to download the required data",
    "section": "",
    "text": "In order to download the required data for the excersices in this virtual resource you will find the datasets for free acces in (I guess this will not be the definitive repository, but for the moment I will write mine) this GitHub repository."
  },
  {
    "objectID": "01_00_FollowingR.html#introduction",
    "href": "01_00_FollowingR.html#introduction",
    "title": "Following Along with R",
    "section": "Introduction",
    "text": "Introduction\nIn this section we will provide a primer in R, which seeks to provide you with the necessary tools to explore the microeconometric methods introduced throughout the book. R is an open source language focused on statistical computation. R has a long history, dating the early 1980s, and also an ever-growing body of user-contributed add-on packages. It also has an active community providing online support on forums such as Stack Overflow, and a substantial corpus of code online, meaning that large language models will be well suited to support you in your programming in R. It provides you with the large majority of tools you will need throughout this book, as well as the programming environment necessary to extend available tools where required.\nThe goal of this site is not to provide you with a comprehensive introduction to the language, but instead we it seeks to provide you with an overview of the basic tools to understand the required tools that we will use to get up and running in this book. In the first section we will focus on a brief rundown of some principal elements of R without yet getting into the empirical methods discussed in the textbook. Thereafter, we will focus on causal econometric methods, but in each section will also introduce any further tools required to complete key analyses or end-of-chapter questions. The goal of this resource is that after following along with these sections you will be sufficiently well-versed in R that you will comfortably be able to work with real data and econometric implementations. Nevertheless, below we point you to further resources if you are seeking a comprehensive overview of R as a language."
  },
  {
    "objectID": "01_00_FollowingR.html#installing-and-working-with-r",
    "href": "01_00_FollowingR.html#installing-and-working-with-r",
    "title": "Following Along with R",
    "section": "Installing and Working with R",
    "text": "Installing and Working with R\nInformation on how to download R is available on the R website, and further support can be found searching the web. In general, we recommend that you install an Integrated Development Environment (IDE) such as RStudio. RStudio provides a user-friendly interface for R, allowing you to view any elements that you have generated in the memory in R, output like graphics, help documentation, and so forth. An example of what RStudio looks like is provided below, where you can see that code is visible, as well as graphical output, and information about what is in the your “environment”. For further information on installing RStudio, see the RStudio website. You are of course welcome to use R however you prefer, and you may prefer to edit code in your favourite text editor and execute code from the command line. Throughout the rest of these resources, we will assume that you have R installed on your computer and have some way to interact with it, either via an IDE or some other work flow that suits you.\n\n\n\nRStudio screenshot"
  },
  {
    "objectID": "01_00_FollowingR.html#further-resources",
    "href": "01_00_FollowingR.html#further-resources",
    "title": "Following Along with R",
    "section": "Further Resources",
    "text": "Further Resources\nFrom here we will move to a first tutorial about R as a language, and an overview of a number of hey elements. If you are interested in generating a more complete overview of R, a number of free resources can be consulted, such as the following books provided free online:\n\nWickham, H., Cetinkaya-Rundel, M. & Grolemund, G. (2023). R for Data Science . O’Reilly Media. 2nd Edition.\nWickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis, Springer-Verlag New York. Link\n\nWilke, C. (2019). Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures. O’Reilly Media. 1st Edition. Link\n\nA range of other textbooks are available that may help you with your work in R including:\n\nMatloff, N., (2011) The Art of R Programming, No Starch Press.\n\nand, with a particular focus on economics and causal methods:\n\nHuber, M., (2023) Causal Analysis: Impact Evaluation and Causal Machine Learning with Applications in R, MIT Press."
  },
  {
    "objectID": "01_01_IntroductionR.html",
    "href": "01_01_IntroductionR.html",
    "title": "An Introduction to R",
    "section": "",
    "text": "Preliminaries\nWe will assume that when you are reading this you have downloaded R and have been able to access R in some way. This may be via the command line, but most likely we imagine you will have some GUI which allows you to see a number of windows including a space for graphical output, a description of the contents of your R Environment (for example any data you have loaded), potentially a place to write your code in R, and, most importantly, a “shell”, or R interface, which looks like the following:\n\nR --no-save\n\nHere, R code can be entered directly following a prompt which is the > symbol at the bottom of the window above. From the moment you open R you are in an R session until the moment you close it, from now on understand a session as this time between you open and close R. The most simple way to execute code in Ris to simply input commands into your R console. So, for example, you could write the following at to the right of the > symbol, and R will evaluate this code:\n\n4 + 4\n\n[1] 8\n\n\nAs you can see, R has understood the instruction that you want to add 4 plus 4 and show the result, which is evaluated, and output directly below the code in the R console. Later in this chapter we will properly explain these mathematical operations and the different R data types. Beyond evaluating such simple mathematical operations, R has a host of in-built functions which can be invoked at the command line. While we will interact with this in more detail later, a simple example is the following, which you can type in your R console:\n\ngetwd()\n\n[1] \"C:/Users/Usuario/Desktop/Prim_2023/Ayudantias/Investigación/Clarke_MicroeconometriaCausalidad/Ejemplo_QuartoBook\"\n\n\nThis function which can be understood as “get working directory” will show you the path on your computer where R is currently working. Thus, any files saved will be exported there, and R will search for any thing to import from this directory. If you want to change this directory you must use the function setwd(\"Path/to/the/directory/you/want/to/use\") with the path written between \" \" or ' ' in order to R understand that is a character, again a topic that will be seen deeper latter. It is important to note that paths should be separated with the slash character: / rather than the backlash \\, and this will work on any operating system. Indeed, if you try to set directoris with a backslash, you will see that R returns an error.\nFunctions is also a topic we are going to see deeper latter. Anyways, until now we have just execute code in the console, but with this unless you watch out for the history, you may loose the code between sessions, so is highly recommended to register your code in R Scripts. What are scripts? Are text files that R understands it like code to execute, all you write in a script R will interpret it as code to execute unless you have the # character to the left. For example if you type in your script\n\n\n\nAn R Script and Output in RStudio\n\n\n\nprint(\"Hello World\")\n\n[1] \"Hello World\"\n\n\nR will understand that you are giving the instruction to print the character Hello World, but instead if you type\n\n# print(\"Hello World\")\n\nR will do nothing because interpret all to the right from the # as plain text and not code with instructions to follow. Note that is said “all to the right from the #”, this implies that it can be used in the same line as code\n\nprint(\"Hello World\") # To the left of # code, all to the right, plain text\n\n[1] \"Hello World\"\n\n\nAs you can see it executes the instruction to the left from # but ignores all to the right, this plain text is known as comment and is always a good practice in programming to include a few comments in your script explaining in general terms what are you doing. The previous idea helps you when revise old scripts and when share your code work with others.\n\nAn introduction to language and data types\nUntil now we have executed some code in R, some of this code can made internal changes as the setwd function, some of this code show an specific result as print function and other just execute an action and show result as 4 + 4, but just doing and showing it, not storing this result. In order to store the results of your procedures you can define a variable or an object using one of the next symbols: ->, = or <-. Now is shown an example where is asigned a variable named x with different numbers:\n\nx <- 1\nx\n\n[1] 1\n\nx = 2\nx\n\n[1] 2\n\n3 -> x\n\nWith the use of -> or <- is clearly how R assign the value, but with the use of = you must be cautelous of do it the way name = value, if not, there will be an error:\n\n4 = x\n\nError in 4 = x: lado izquierdo de la asignación inválida (do_set)\n\n\nAll the way long in your sessions you could see this type of messages, this messages points you different types of details:\n- Error: This kind of messages are telling you that something gone wrong and R couldn’t execute the code you type. Usually they include a brief explanation of the error for you to debugging it.\n- Warning: This kind of message are telling you that something that may cause you problems occured. R will still execute the code and give the result, but warning you that not everything is in order and may cause inaccurate results o future problems. Some times this messages are something that you can ignore and get your results correctly but some other times it may cause you problem, so you should give a minute to read it, understand it and evaluate if is necessary to fix it.\n- Message: This kind of message are only providing information about the execution, R telling something is considered good to know. Not necessary are errors or warnings, sometimes just comunicate of procedures.\n\nData Types\nNow that you know how to store a value in an object and some of the messages you can get, you should know that R has different data types for this objects, some of them are character, numeric, arrays, data frames and lists as an example. Different types of data allows different ways to operate with it, for example characters must be specified between \" \", or ' ', otherwise R will understand them as variables names. For example if you want to write Hello World the next try will give you an error:\n\nHello World\n\nError: <text>:1:7: unexpected symbol\n1: Hello World\n          ^\n\n\nIn change, the next code understands that is a character:\n\n\"Hello World\"\n\n[1] \"Hello World\"\n\n\nA function that allows you to know which data type is an object is class, for example if you type class(\"Hello World\") it will return \"character\"\n\nclass(\"Hello World\")\n\n[1] \"character\"\n\n\nAs previous, if you don’t input the between \" \" it will return an error pointing that the object doesn’t exists\n\nclass(Hello World)\n\nError: <text>:1:13: unexpected symbol\n1: class(Hello World\n                ^\n\n\nNumeric data doesn’t need to be inputted between \" \" or ' ', in fact if is inputted between \" \" or ' ', R will understand it as a character instead a number. For example if you type just 2 the output will be a number, instead if you type \"2\" the output will be printed between \" \", pointing that element is a character\n\n2\n\n[1] 2\n\n\"2\"\n\n[1] \"2\"\n\n\nYou can check also with the class function\n\nclass(2)\n\n[1] \"numeric\"\n\nclass(\"2\")\n\n[1] \"character\"\n\n\nOther option of obecjts are vectors or arrays, this types allows to create objectis with multiple elements and an easy way to create them is with the function c, that stands for combine. For example if you want to produce an object with two elements if you just type them without the c function will be an error\n\n1 2 \n1,2\n\nError: <text>:1:3: unexpected numeric constant\n1: 1 2\n      ^\n\n\nInstead, if you use the c function it will create an object with multiple elements\n\nc(1,2)\n\n[1] 1 2\n\n\nA precaution is how you mix other data types in the objects that combine different elements because different data types will influence the way this combination works. For example vectors will coerce to the most restrictive data type, if you mix characters with numbers in a vector, R will coerce the vector type to a character\n\nclass(c(1,2))\n\n[1] \"numeric\"\n\nclass(c(1,\"2\"))\n\n[1] \"character\"\n\n\nYou can also create arrays with the matrix function, this allows you to get objects in two dimensiones, rows and columns\n\nmatrix(c(1,2,3,4), nrow = 2)\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\n\nAn inconvenient from arrays is that, as vectors do, coerce to the more restrictive data type\n\nmatrix(c(1,2,3,\"4\"), nrow = 2)\n\n     [,1] [,2]\n[1,] \"1\"  \"3\" \n[2,] \"2\"  \"4\" \n\n\nOne of the data types that works along with mutliple othe types are data frames, this allows to create a standard data base as you tipically know with multiple rows and columns, where an entire column will coerce to the most restrictive data type but you can have different data types in different columns. As an example we create a data frame named df that will use later in other examples\n\ndf <- data.frame(A = c(1, 2, 3), B = c(4, 5, 6), \n                 C = c(\"XXX\", \"YYY\", \"ZZZ\"))\ndf\n\n  A B   C\n1 1 4 XXX\n2 2 5 YYY\n3 3 6 ZZZ\n\n\nLater we will introduce a data type named tibble that is very similar to data frames, with a few differences, and is common to work with it in the tidyverse that will be explained later. The last data type of this section will be lists, this one allows to store any data type you imagine, you can combine in one object characters, numbers or data frame, within other objects, and is that the reason multiple functions that will explore later will return it results as a list or an object created from a list. An example of this lists are the next one, where we create an object named l that is a list we will use later in other examples.\n\nl <- list(Character = c(\"Hello\", \"World\"), Number = c(1, 2, 3, 4),\n          DataFrame = df)\n\n\n\nSubset Multidimensional Elements\nAs you see previously, there is elements as data frames or lists that stores multiple elements. Sometimes you will want to work with a subset of this multidimensional data types instead the entire object. In data frames, or lists, you can easily access to an entire column, or object, by using $ followed by the column, or object, name:\n\ndf$A\n\n[1] 1 2 3\n\nl$Character\n\n[1] \"Hello\" \"World\"\n\n\nBut sometimes you may want to access more, or less, than one entire column or object, so the more generally way to access to the elements are with the use of [ ]. One dimension objects like vectors or a column of a data frame, allows to access its elements by using the number of the element position between [ ]\n\ndf$A[1]\n\n[1] 1\n\n\nThis syntax allows also to access more than one object by combining it with a vector\n\ndf$A[c(1, 3)]\n\n[1] 1 3\n\n\nIn case of multidimensional elements as an entire data frame or arrays you should use [row,column] syntax, if you want an entire row just left in blank the row position\n\ndf[,1]\n\n[1] 1 2 3\n\n\nAnd the same for an entire row\n\ndf[1,]\n\n  A B   C\n1 1 4 XXX\n\n\nYou can also mix a single element and more than one row, or column\n\ndf[2,2]\n\n[1] 5\n\ndf[c(1,3), 2]\n\n[1] 4 6\n\n\nIn lists you must use a slight syntax, first you must access the object with double [ ] and then once you access the object it works like the object do. For example, now we show how to access the data frame that is the third object of the list, and then the element of the second row and second column\n\nl[[3]][2,2]\n\n[1] 5\n\n\nBetween [ ] you can also use the elements names when calling an object inside a list of a column in a data frame. The next code replicates the previous example\n\nl[[\"DataFrame\"]][2,\"B\"]\n\n[1] 5\n\n\n\n\nBasic Operations\nNow that you know how to store data, and the different objects where you can store the data, you must know the basic operations to do with that data. R has the next basic mathematical operations:\n\n\n\nSymbol\nOperation\n\n\n\n\n+\nAddition\n\n\n-\nSubtraction\n\n\n*\nMultiplication\n\n\n/\nDivision\n\n\n** or ^\nPower\n\n\n%%\nModulus\n\n\n%/%\nInteger Division\n\n\n\nA few examples\n\n10 + 3\n\n[1] 13\n\n10 - 3\n\n[1] 7\n\n10 * 3\n\n[1] 30\n\n10 / 3\n\n[1] 3.333333\n\n10 ^ 3\n\n[1] 1000\n\n10 ** 3\n\n[1] 1000\n\n10 %% 3\n\n[1] 1\n\n10 %/% 3\n\n[1] 3\n\n\nAlso when you combine different operators it respect the PEMDAS order, first solve Parenthesis, second solve Exponents, third Multiplication, fourth Division, fifth Addition and sixth Substraction. For example in order to solve \\[-\\frac{5 + 3^{5-3}}{5\\times 3}\\] You should use the code\n\n-(5+3^(5-3))/(5*3)\n\n[1] -0.9333333\n\n\nR also has logical operatos that returns a boolean value (TRUE or FALSE, also abbreviated as T or F) pointing if the statement is true or false. This operators are:\n\n\n\nSymbol\nComparison\n\n\n\n\n==\nEquals\n\n\n!=\nDifference\n\n\n>\nGreater\n\n\n>=\nGreater or Equal\n\n\n<\nLess than\n\n\n<=\nLess than or Equal\n\n\n%in%\nIf it is in\n\n\n|\nOr\n\n\n&\nAnd\n\n\n\nA few examples\n\n4 == 3\n\n[1] FALSE\n\n4 != 3\n\n[1] TRUE\n\n4 > 3\n\n[1] TRUE\n\n4 >= 3\n\n[1] TRUE\n\n4 < 3\n\n[1] FALSE\n\n4 <= 3\n\n[1] FALSE\n\n4 %in% c(1,2,3,4)\n\n[1] TRUE\n\nTRUE | FALSE\n\n[1] TRUE\n\nTRUE & FALSE\n\n[1] FALSE\n\n\nThis boolean values are interpreted by R as the numbers 0 for F and 1 for T, characteristic that allows to work with them numerically and is useful when you want to check a series of conditions.\nThe logical and mathematical operators are useful when making operations between different objects, it can be an object of a single valur or an object with multiple values. As many software R came with some basic functions that make specific tasks, for example if you want to add all the values in a vector you don´t need to type one-by-one all those values, you can use the function sum:\n\nsum(df$A)\n\n[1] 6\n\n\nIn order to use this functions the syntaxis in R is the function’s name followed by parenthesis ( ) and between the parenthesis the function’s arguments separated by comma ,. To know better how a function works is always a good idea to read the help document that comes along with R, some that you can make with ? symbol. For an example if you type ?sum you will see how sum function works and its arguments, where you can see an argument na.rm = FALSE, this points that the default value of the argument is FALSE and if you keep reading a little forward you can see that the documentation indicates for this argument: logical. Should missing values (including NaN) be removed? telling you the type of value that you can use and what is the functionality. Let x be a vector with a missing value NA\n\nx <- c(1, 2, NA)\n\nIf you use the sum function you will get an NA value\n\nsum(x)\n\n[1] NA\n\n\nBut if you use the na.rm argument you will get the sum of the valid values\n\nsum(x, na.rm = TRUE)\n\n[1] 3\n\n\nAs the sum function, R comes with a lot of functions in their base environment as functions to get descriptive statistics, work with dates and others. This functions are sufficient to take along any task manually but not necesarilly optimally. There are very useful functions and data types that doesn’t come with base enviroment and comes with packages.\n\n\n\nManaging packages\nWhat are packages? Packages is a group of functions and data types that works within them and other functions in R, this packages contains data types definitions, variables definitions and functions that realize some specific procedures. In order to install a package you have several alternatives depending on what is the package’s source, but no matter the option is the case, the procedure must be done only once in your R enviroment. Now is explained how to do it from CRAN by using the function install.packages() writing within \" \" the package name. As an example, in order to install dplyr -that is one of the most famous R’s packages for data manipulation- you must execute the following code:\n\ninstall.packages(\"dplyr\")\n\nNow that the package is installed you doesn’t need to install it again unless you want to update the package. That a package is installed doesn’t mean that R automatically loads the package along with their functions and data types, for example if you want to use the dplyr’s function mutate to create a new variable in your data frame it will be an error if you haven’t load the dplyr package:\n\nmutate(df, C = A + B)\n\nError in mutate(df, C = A + B): no se pudo encontrar la función \"mutate\"\n\n\nSo in order to use the package you must load it each time you open a new session with the function library() writing the package’s name within \" \" as follows\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nNow if you want to use the dplyr’s function mutate it will work\n\nmutate(df, C = A + B)\n\n  A B C\n1 1 4 5\n2 2 5 7\n3 3 6 9\n\n\nIs highly recommended that the load of the package be included in your script for reproducibility of your code.\nA situation that you may encounter in your R work is that sometimes you may want to use two packages that have different functions with the same name. As an example if you see the message that R print when you loaded dplyr package this says “The following objects are masked from ‘package:stats’:” and next it points the functions filter and lag, this message means that the package stats -one of the automatically installed and loaded by R- also has functions with the names filter and lag, but when you use them R will use the dplyr’s functions. For example the next code use dplyr’s lag\n\nlag(df$A)\n\n[1] NA  1  2\n\n\nBut in order to use the masked functions you can use the syntaxis package::function, following the previous example, to use stats’s lag\n\nstats::lag(df$A)\n\n[1] 1 2 3\nattr(,\"tsp\")\n[1] 0 2 1\n\n\n\n\nLoading and viewing data\nIn this section we review how to import classical data formats as csv, txt, excel and dta. The first doesn’t need specific packages to work well, but the latters do.\nFor csv and txt data R comes with the functions read.csv, read.csv2, read.delim and read.delim2. If you see the help documentation you will see that the four of them belongs to the family of the read.table function and has a very similar usage, being the basic usage:\n\nread.table(file = \"Path/To/Your/File.csv\")\n\nNote that the example is made with csv but is the same for txt. If you explore the help documentation you will notice that you can specify a variety of arguments that indicates if the first row should be taken as a header row, what is the separation between columns, the decimal separator and others.\nFor excel files you count with a variety of packages such as readxl, openxlsx and xlsx. Each package has their function and allows different tasks as read or write depending on the package. As this section is focused on import data, we present an example of the readxl package’s family of functions read_xls, read_xlsx and read_excel\n\nread_xlsx(path = \"Path/To/Your/File.xlsx\")\n\nIf you see the help documentation you will catch that there are a variety of arguments that allows point an specific sheet to impor, an specific range, use or not the first row as column names, between others.\nFinally in order to import dta files the package will be haven and the functions read_stata or read_dta, both with the basic usage as follows\n\nread_dta(file = \"Path/To/Your/File.dta\")\n\nUntil now all examples only import data but not store it in any object, an action that doesn’t make much sense because probably you import data to work with it. Now we are going to import an internal dataset from the package wooldridge, that contains 115 data sets from the book “Introductory Econometrics: A Modern Approach”, 7th Edition by Jeffrey Wooldridge, in order to show how manipulate this data sets\n\nmroz <- wooldridge::mroz\n\nThis dataset contains the data from T. A. Mroz (1987), “The Sensitivity of and Empirical Model of Married Women´s Hours of Work to Economic and Statistical Assumptions”, Econometrica 55, 765-799.\n\n\nTyding data\nIn this section we are covering how to manipulate data, specifically how to make a simple exploratory analysis and modify the data frame. Note that the dataset is imported as a data frame\n\nclass(mroz)\n\n[1] \"data.frame\"\n\n\nAlong with this section you will see the use of the head function, this function shows us the first rows of an object in order to prevent a data frame being totally printed. Previously we mentioned the existence of tibbles that are a widely used structure similar to data frames but with a few differences like don’t consider rownames or don’t interpret strings as factors by default. We introduce this because with the use of some functions from dplyr package a data frame becomes automatically a tibble. For example, consider de mroz data frame, if we apply the combination of group_by and summarise functions to get the mean of the number of kids with less than 6 years by labor situation of the women:\n\nungroup(summarise(group_by(mroz, inlf), meankidslt6 = mean(kidslt6)))\n\n# A tibble: 2 × 2\n   inlf meankidslt6\n  <int>       <dbl>\n1     0       0.366\n2     1       0.140\n\n\nAs you can see the result is a tibble. Now that you have an example of the use of dplyr you can see how easily is to get confused by using too many functions at once, a really nice operator that comes with dplyr is the pipe operator %>% that allows to apply functions without writing all together. As an example the next code replicates the previous example:\n\nmroz %>% group_by(inlf) %>% summarise(meankidslt6 = mean(kidslt6)) %>%\n  ungroup()\n\n# A tibble: 2 × 2\n   inlf meankidslt6\n  <int>       <dbl>\n1     0       0.366\n2     1       0.140\n\n\nNote that this works as: to the object at the left of the pipe operator, apply the function to the right. Another thing you can note is the use of the group_by, summarise and ungroup combo, where group_by as the name says allows to group by the variable(s) indicated, summarise calculate a descriptive statistic that can be mean, sd, min, max, median, quantile and others, in order to know them all you should consult the help documentation of summarise function.\nOther functionalities of dplyr package are the use of sql functions like sql_join that allows to merge two data frames or tibbles, apply functions to every column or specific ones, among others. Another famous package for data manipulation is tidyverse, a package that comes along with other package as dplyr, tibble, tidyr and others like ggplot2 for plots, lubridate for dates, stringr for strings. This fact became tidyverse as one of the must have package for data manipulation but with the caution that it takes up more memory.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.4\n✔ ggplot2   3.4.1     ✔ stringr   1.5.0\n✔ lubridate 1.9.2     ✔ tibble    3.2.1\n✔ purrr     1.0.1     ✔ tidyr     1.3.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\n\nOnce loaded tidyverse package, you can use all the tools in the packages that are loaded with tidyverse. So let’s now try to make a join between two data frames (tibbles), first create the mean as previous examples and next join this mean to the mroz dataset by the column inlf\n\nmroz %>% group_by(inlf) %>% summarise(MeanKidslt6 = mean(kidslt6)) %>%\n  ungroup() %>% right_join(mroz, by = \"inlf\")\n\n# A tibble: 753 × 23\n    inlf MeanKidslt6 hours kidslt6 kidsge6   age  educ  wage repwage hushrs\n   <int>       <dbl> <int>   <int>   <int> <int> <int> <dbl>   <dbl>  <int>\n 1     0       0.366     0       0       1    49    12    NA       0   2550\n 2     0       0.366     0       2       0    30    16    NA       0   1928\n 3     0       0.366     0       1       0    30    12    NA       0   1100\n 4     0       0.366     0       0       4    41    12    NA       0   3193\n 5     0       0.366     0       0       1    45    12    NA       0   2250\n 6     0       0.366     0       0       5    43    12    NA       0   2012\n 7     0       0.366     0       0       1    42    13    NA       0   3856\n 8     0       0.366     0       0       0    60    12    NA       0   1645\n 9     0       0.366     0       0       0    57    12    NA       0   1554\n10     0       0.366     0       0       2    38    10    NA       0   2352\n# ℹ 743 more rows\n# ℹ 13 more variables: husage <int>, huseduc <int>, huswage <dbl>,\n#   faminc <dbl>, mtr <dbl>, motheduc <int>, fatheduc <int>, unem <dbl>,\n#   city <int>, exper <int>, nwifeinc <dbl>, lwage <dbl>, expersq <int>\n\n\nNote that the result of this procedure hasn’t been store in any object, so it can’t be accessed later. Other convenient tools that you will apply on this book are selecting some rows or some columns from the dataset, from filter function we can filter rows that meet certain condition and from the use of select we can filter specific columns:\n\nmroz %>% select(kidslt6, hours) %>% filter(kidslt6 > 2)\n\n  kidslt6 hours\n1       3     0\n2       3     0\n3       3     0\n\n\nIn previous section has been shown the use of mutate function to create new variables, in tibbles as in data frames the use of $ operator also creates new variables:\n\nmroz$exper2 <- mroz$exper^2\nhead(mroz)\n\n  inlf hours kidslt6 kidsge6 age educ   wage repwage hushrs husage huseduc\n1    1  1610       1       0  32   12 3.3540    2.65   2708     34      12\n2    1  1656       0       2  30   12 1.3889    2.65   2310     30       9\n3    1  1980       1       3  35   12 4.5455    4.04   3072     40      12\n4    1   456       0       3  34   12 1.0965    3.25   1920     53      10\n5    1  1568       1       2  31   14 4.5918    3.60   2000     32      12\n6    1  2032       0       0  54   12 4.7421    4.70   1040     57      11\n  huswage faminc    mtr motheduc fatheduc unem city exper  nwifeinc      lwage\n1  4.0288  16310 0.7215       12        7  5.0    0    14 10.910060 1.21015370\n2  8.4416  21800 0.6615        7        7 11.0    1     5 19.499981 0.32851210\n3  3.5807  21040 0.6915       12        7  5.0    0    15 12.039910 1.51413774\n4  3.5417   7300 0.7815        7        7  5.0    0     6  6.799996 0.09212332\n5 10.0000  27300 0.6215       12       14  9.5    1     7 20.100058 1.52427220\n6  6.7106  19495 0.6915       14        7  7.5    1    33  9.859054 1.55648005\n  expersq exper2\n1     196    196\n2      25     25\n3     225    225\n4      36     36\n5      49     49\n6    1089   1089\n\n\nAnother function to create variables is transmute, but this function doesn’t mantain old variables, in fact it replace all the data for the new one\n\nhead(mroz %>% transmute(expersquared = exper^2))\n\n  expersquared\n1          196\n2           25\n3          225\n4           36\n5           49\n6         1089\n\n\n\n\n\nSo it must be used with caution. Finally the last tool that we introduce for data manipulation is transform data from wide format to long format and reverse. Consider the next data frame\n\nData <- data.frame(Zone = c(\"A\", \"A\", \"B\", \"B\"), \n                   Year = c(2021, 2022, 2021, 2022),\n                   Sales = c(100, 115, 98, 106))\nData\n\n  Zone Year Sales\n1    A 2021   100\n2    A 2022   115\n3    B 2021    98\n4    B 2022   106\n\n\nThis format is the long format, you have multiple observations for one unit (zone in this example), to transform it in wide format\n\nData = pivot_wider(data = Data, id_cols = Zone, names_from = Year,\n                   values_from = Sales)\nData\n\n# A tibble: 2 × 3\n  Zone  `2021` `2022`\n  <chr>  <dbl>  <dbl>\n1 A        100    115\n2 B         98    106\n\n\nAs you can see now there is one observation per unit. Lets get it back to long format\n\nData = pivot_longer(data = Data, names_to = \"Year\", values_to = \"Sales\",\n                    cols = -Zone)\nData\n\n# A tibble: 4 × 3\n  Zone  Year  Sales\n  <chr> <chr> <dbl>\n1 A     2021    100\n2 A     2022    115\n3 B     2021     98\n4 B     2022    106\n\n\nNow that you know the basics of data manipulation, the next step is to learn how make some basic plots.\n\n\n\n\n\nBasic Plots\nThe basic function to make a plot in R is the plot function, this function maps pairs of points in the \\((x,y)\\) coordinate axis. Let \\(x\\) be a sequence of integers between -5 and 5\n\nx <- -5:5\n\nNow consider \\(y = x^2\\)\n\ny = x^2\n\nplot function by default maps a point plot\n\nplot(x,y)\n\n\n\n\nIf you access help documentation for plot you can see how add elements to the graph\n\nplot(x,y, type = \"l\", main = \"Plot Example\", xlab = \"Variable X\",\n     ylab = \"Variable Y\")\n\n\n\n\nA widely used package for make more custom graphs is ggplot2, as tidyverse has been loaded previous, in this case we don’t need to load ggplot2, but if you haven’t load it remember that with the next code you can do it\n\nlibrary(ggplot2)\n\nThe first step in ggplot is to define the plot\n\nggplot()\n\n\n\n\nThis define a blank canvas where you can add elements, as an example a line object (geom) is added\n\nggplot() + geom_line()\n\n\n\n\nUntil now we haven’t added data so ggplot2 is not mapping any pair of points, now specify the data, this must be done inside the aes function\n\nggplot() + geom_line(aes(x = x, y = y))\n\n\n\n\nNote that in order to add elements to the graph we have been using + unlike when using multiple variables where were used the pipe operator %>%. With this syntax you can add more elements to the graph\n\nggplot() + geom_line(aes(x , y)) + geom_point(aes(x, y))\n\n\n\n\nWhen you use a data frame you can also define aes inside ggplot function\n\nggplot(mroz, aes(x = exper, y = lwage)) + geom_point()\n\n\n\n\nHere you can manipulate different overall themes for your plot and elements characteristics such as color or size\n\nggplot(mroz, aes(x = exper, y = lwage)) + geom_point(color = \"red\") +\n  theme_minimal()\n\n\n\n\nIn this way you can add a variety of elements such as an OLS regression line\n\nggplot(mroz, aes(x = exper, y = lwage)) + geom_point(color = \"red\") +\n  theme_minimal() + geom_smooth(method = \"lm\", color = \"blue\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nAs said before, this introductory section of this chapter doesn’t intend to be a comprehensive tutorial of R, instead is a wide general guide to understand some fundamentals you will see in the rest of the chapter."
  },
  {
    "objectID": "01_02_Chapter2R.html",
    "href": "01_02_Chapter2R.html",
    "title": "Details required for Chapter 2",
    "section": "",
    "text": "Here will be the Chapter 2 excersises and examples."
  },
  {
    "objectID": "01_03_Chapter3R.html",
    "href": "01_03_Chapter3R.html",
    "title": "Details required for Chapter 3",
    "section": "",
    "text": "Here will be the Chapter 3 excersises and examples."
  },
  {
    "objectID": "02_00_FollowingStata.html#introduction",
    "href": "02_00_FollowingStata.html#introduction",
    "title": "Following Along with Stata",
    "section": "Introduction",
    "text": "Introduction\nIn this section we will provide a primer in Stata, which seeks to provide you with the necessary tools to explore the microeconometric methods introduced throughout the book. “Stata is a complete, integrated software package that provides all your data science needs—data manipulation, visualization, statistics, and automated reporting” as is defined in its website. Stata has a long history, dating the middle 1980s, and also an ever-growing body of user-contributed add-on packages. It also has an active community providing online support on forums such as Stata List, and a substantial corpus of code online, meaning that large language models will be well suited to support you in your programming in Stata. It provides you with the large majority of tools you will need throughout this book, as well as the programming environment necessary to extend available tools where required.\nThe goal of this site is not to provide you with a comprehensive introduction to the software, but instead we it seeks to provide you with an overview of the basic tools to understand the required tools that we will use to get up and running in this book. In the first section we will focus on a brief rundown of some principal elements of Stata without yet getting into the empirical methods discussed in the textbook. Thereafter, we will focus on causal econometric methods, but in each section will also introduce any further tools required to complete key analyses or end-of-chapter questions. The goal of this resource is that after following along with these sections you will be sufficiently well-versed in Stata that you will comfortably be able to work with real data and econometric implementations. Nevertheless, below we point you to further resources if you are seeking a comprehensive overview of Stata as a software."
  },
  {
    "objectID": "02_00_FollowingStata.html#installing-and-working-with-stata",
    "href": "02_00_FollowingStata.html#installing-and-working-with-stata",
    "title": "Following Along with Stata",
    "section": "Installing and Working with Stata",
    "text": "Installing and Working with Stata\nInformation on how to order and get Stata is available on the Stata website, and further support can be found searching the web. Stata also provide a user-friendly interface, allowing you to view any variable that you have generated in the memory in Stata, output like graphics, help documentation, and so forth. An example of what Stata looks like is provided below, where you can see that code is visible, as well as what is in the your “variables”, a history of code and results window.\nAQUI PODRIAMOS INCLUIR UN PANTALLAZO DE STATA, QUIZAS PODRIA SER EL SUYO PROFESOR"
  },
  {
    "objectID": "02_00_FollowingStata.html#further-resources",
    "href": "02_00_FollowingStata.html#further-resources",
    "title": "Following Along with Stata",
    "section": "Further Resources",
    "text": "Further Resources\nFrom here we will move to a first tutorial about Stata as a language, and an overview of a number of hey elements. If you are interested in generating a more complete overview of Stata, a number of resources can be consulted in the Stata webpage."
  },
  {
    "objectID": "02_01_IntroductionStata.html",
    "href": "02_01_IntroductionStata.html",
    "title": "Introduction to Stata and Basic Tools Required for this book",
    "section": "",
    "text": "From the moment you open Stata you are into an Stata session until the moment you close it, from now on understand a session as this time between you open and close Stata. A good idea when working with Stata is to use Stata Projects who allows you to organize into a better way your enviroment in a self-contained folder, where all the documents (input or output) by default will be in that folder unless you define subfolders or specify the entire path in your computer to other folders, for more information you may consult Stata webpage. In order to execute code you should input the code in your Stata command window, that is the place where Stata receive instructions and execute them, so if you input in your command window\n\ndisplay 4 + 4\n\n8\n\n\nStata will understand the instruction that you want to add 4 plus 4 and show the result, latter in this chapter we will explain more about mathematical operations and the different Stata data types. Another example of Stata execution is that if you type in your console:\n\npwd\n\nC:\\Users\\Usuario\\Desktop\\Prim_2023\\Ayudantias\\Investigación\\Clarke_Microeconome\n> triaCausalidad\\Ejemplo_QuartoBook\n\n\nStata will show you the path to the current working directory, the folder where Stata understand is working. If you want to change this directory you must use the command cd \"Path/to/the/directory/you/want/to/use\" with the path written between \" \" in order to Stata understand that is a character, again a topic that will be seen deeper latter. Another important thing is that you should type path with / because some operative systems don’t recognize backslash \\.\nCommands is also a topic we are going to see latter. Anyways, until now we have just execute code in the console, but with this unless you watch out for the history, you may loose the code between sessions, so is highly recommended to register your code in Do Files. What are do files? Are text files that Stata understands it like code to execute, all you write in a do file, Stata will interpret it as code to execute unless you have the * character at the beginning of the line or the characters // between code and this plain text. For example if you type in your script\n\ndisplay \"Hello World\"\n\nHello World\n\n\nR will understand that you are giving the instruction to print the character Hello World, but instead if you type\n\n* print(\"Hello World\")\n\nStata will do nothing because interpret all the line that begins with * as plain text and not code with instructions to follow. Note that was also pointed the use of //, this can be used in the same line as code\n\ndisplay \"Hello World\" // All to the right, plain text\n\nHello World\n\n\nAs you can see it executes the instruction to the left of // but ignores all to the right, this plain text is known as comment and is always a good practice in programming to include a few comments in your script explaining in general terms what are you doing. The previous idea helps you when revise old scripts and when share your code work with others.\n\nAn introduction to language and data types\nUntil now we have executed some code in Stata, some of this code can made internal changes as the cd command and other just execute an action showing its results as display 4 + 4, but just doing and showing it, not storing this result. In order to store a result you must follow the syntaxis command name = value, where the command will be specific of the object type, the name will be whatever you want to call the result you are storing and the value can be an specific value or the result of an operation, now we introduce a variety of object types in Stata and we explore further the topic of the data types this objects store in the next subsection.\nThe most common objects to work in Stata are scalars, matrices and the datasets. Scalars are objects that store a single value, this value can be either a string or a number, data types we will analyze latter, and can be defined as follow\n\nscalar x1 = \"Hello World\"\ndisplay x1\nscalar x2 = 4 + 4\ndisplay x2\n\nHello World\n\n\n8\n\n\nThis code succesfully store the string Hello World in the scalar named x1 and 8 (as the result of 4 plus 4) in the scalar x2. This scalars can also be used in future operations\n\nscalar x3 = x2 + 4\ndisplay x3\n\n12\n\n\nMatrices can store only numbers and works like usual algebraic matrices, in order to create a matrix you must use\n\nmatrix input A = (1, 2 \\ 3, 4)\nmatrix input B = (5, 6 \\ 7, 8)\n\nIn order to see this matrices\n\nmatrix list A\nmatrix list B\n\nA[2,2]\n    c1  c2\nr1   1   2\nr2   3   4\n\n\nB[2,2]\n    c1  c2\nr1   5   6\nr2   7   8\n\n\nThis matrices are stored and we can operate with them latter\n\nmatrix define C = A * B\nmatrix list C\n\nC[2,2]\n    c1  c2\nr1  19  22\nr2  43  50\n\n\nFinally in datasets the data is organized as rectangular table where each column is understand as a variable and each row is understand as an observation. This datasets can be imported from externals files, there are some internals and also can be accessed from the web, a topic we will see deeper latter, for now as an example we use one of the Stata internals datasets in order to show you how they work. With the following code you will charge the dataset auto.dta\n\nsysuse auto\n\nIf you use the browse command, Stata will deploy a new window where will show you this data set\n\nbrowse\n\nIn this window you can see that each column represent a different variable and each row is a different observation. Also you can see data in different color, some columns in black (numeric), other in red (string) and other in blue (numeric, but labeled), a topic we will see latter when talk about data types. As you can see this kind of object allows to store different data types and multiple variables, so is very useful.\nIn one of the recent versions of Stata (specifically the version 16) were introduced the Frames objects, this are data frames that allows to store multiple data sets simultaneously in the memory of Stata and switch between them whenever you want. For example now that you have imported the dataset auto.dta you can see that there is a current data frame named default\n\nframe\n\nIn order to chante this data frame name you can use frame rename oldname newname\n\nframe rename default auto\n\nNow we will create a new data frame with frame create name and change to that data frame with cwf name\n\nframe create secondframe\ncwf secondframe\n\nAs you can see the dataset that were stored previously is no longer seeable in your interface, but if you use\n\nframes dir\n\nYou will see how there is two data frames and the one named auto has the data set stored previously. If you go back to this data frame with\n\ncwf auto\n\nYou will see available again the auto dataset. Now we show you how can have multiple datasets simultaneously in Stata with this data frame. First go back to the data frame second with cwf and then we import other internal dataset named lifeexp\n\ncwf second\nsysuse lifeexp\n\nYou can see that the dataset has changed and you have new data in your dataset, now you can change between this datasets with cwf name and check how the data that is shown in your dataset changes.\nFor further information about the objects we have seen you can consult the help documentation with the help command. For example to see more about frames you can use\n\nhelp frames\n\nYou will see that Stata has deployed a new window with the help documentation for this topic that will show you a lot of information as syntax, descriptions, examples and links to other sections of Stata’s help documentation.\n\nData Types\nNow that you know how to store values in different objects, you should know that Stata has different data types for this objects, some of them are strings and other numerics. Different types of data allows different ways to operate with it, for example characters must be specified between \" \", otherwise Stata will understand them as object’s names and will return an error as don’t recognize them. For example if you want to display Hello World the next try will give you an error:\n\ndisplay Hello World\n\nHello not found\nr(111);\n\nend of do-file\nr(111);\n\n\nIn change, the next code understands that is a character:\n\ndisplay \"Hello World\"\n\nHello World\n\n\nNumeric data doesn’t need to be inputted between \" \", in fact if is inputted between \" \" Stata will understand it as a character instead a number. For example if you type just 2 the output will be a number, and if you type \"2\" the output will be printed as 2\n\ndisplay 2\ndisplay \"2\"\n\n2\n\n2\n\n\nVisually there is no difference with display, but if you try to operate with both of them it will return an error\n\ndisplay \"2\" * 2\n\n2*2 invalid name\nr(198);\n\nend of do-file\nr(198);\n\n\n\n\nBasic Operations\nAt this point we have made a few examples with some mathematical operations, now we introduce a list of a variety of operators that Stata understand for each type of data. We start with the arithmetic ones:\n\n\n\nSymbol\nOperation\n\n\n\n\n+\nAddition\n\n\n-\nSubtraction\n\n\n*\nMultiplication\n\n\n/\nDivision\n\n\n^\nPower\n\n\n\nA few examples\n\ndisplay 10 + 3\ndisplay 10 - 3\ndisplay 10 * 3\ndisplay 10 / 3\ndisplay 10 ^ 3\n\n13\n\n7\n\n30\n\n3.3333333\n\n1000\n\n\nAlso when you combine different operators it respect the PEMDAS order, first solve Parenthesis, second solve Exponents, third Multiplication, fourth Division, fifth Addition and sixth Substraction. For example in order to solve \\[-\\frac{5 + 3^{5-3}}{5\\times 3}\\] You should use the code\n\ndisplay -(5+3^(5-3))/(5*3)\n\n-.93333333\n\n\nWhen you work with strings there are also operators that works, these are + and *. Stata automatically identifies when you use + if you are adding numerical values or concatenating strings, in this case you must use the same data type. When you use * to operate with strings you must specify a string and a number, because Stata will repeat the string as many times as the number indicates\n\nscalar x1 = \"Hello \" + \"World\"\nscalar x2 = 2 + 2\nscalar x3 = \"Hello\" * 2\ndisplay x1\ndisplay x2\ndisplay x3\n\nHello World\n\n4\n\nHelloHello\n\n\nStata also has relational and logical operators that returns a numerical value associated with the truth value of an expression (0 for False and 1 for True) pointing if the statement is true or false. This operators are:\n\n\n\nSymbol\nComparison\n\n\n\n\n==\nEquals\n\n\n!=\nDifference\n\n\n>\nGreater\n\n\n>=\nGreater or Equal\n\n\n<\nLess\n\n\n<=\nLess or Equal\n\n\n|\nOr\n\n\n&\nAnd\n\n\n! or ~\nNegation\n\n\n\nA few examples\n\ndisplay 4 == 3\ndisplay 4 != 3\ndisplay 4 > 3\ndisplay 4 >= 3\ndisplay 4 < 3\ndisplay 4 <= 3\ndisplay (4 == 3) | (4 != 3)\ndisplay (4 == 3) & (4 != 3)\ndisplay ~(4 == 3)\n\n0\n\n1\n\n1\n\n1\n\n0\n\n0\n\n1\n\n0\n\n1\n\n\nAs many softwares Stata hase some basic commands that make specific tasks, for example if you want to calculate some descriptive statistic of a variable in a dataset you don´t need to calculate one-by-one the statistics, you can use the command summarize. As an example, for the dataset auto if you want to get the descriptive statistics of the mpg variable\n\nsummarize mpg\n\n(1978 Automobile Data)\n\n    Variable |        Obs        Mean    Std. Dev.       Min        Max\n-------------+---------------------------------------------------------\n         mpg |         74     21.2973    5.785503         12         41\n\n\nIn order to use this commands the syntaxis in Stata is the command’s name followed by its arguments (variable names, conditionals for a subset of observations and other requirements) and its specific options, separated by a comma the arguments from the options. To know better how a command works is always a good idea to read the help document that comes along with Stata, something that you can make with the help command. As an example if you type help summarize you will see the help documentation for this command, in sepecific note that the syntax will point\n<ins>su</ins>mmarize [varlist] [if] [in] [weight] [, options]\nThe first you can note is that the name of the command has a few letters underline, this means that you can abbreviate the command name to those letters and Stata will understand that you want to use that command. As an example if you type\n\nsu mpg\n\n(1978 Automobile Data)\n\n    Variable |        Obs        Mean    Std. Dev.       Min        Max\n-------------+---------------------------------------------------------\n         mpg |         74     21.2973    5.785503         12         41\n\n\nThen you can see it has some elements between [ ], this means those are optional arguments. In the case of varlist you can specify a list of variables in order to get their descriptive statistics or you can leave it in blank in order to get all variables descriptive statistics\n\nsu price mpg\ndisplay \"-------------- Line to separate outputs --------------\"\nsu\n\n(1978 Automobile Data)\n\n    Variable |        Obs        Mean    Std. Dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         74    6165.257    2949.496       3291      15906\n         mpg |         74     21.2973    5.785503         12         41\n\n-------------- Line to separate outputs --------------\n\n    Variable |        Obs        Mean    Std. Dev.       Min        Max\n-------------+---------------------------------------------------------\n        make |          0\n       price |         74    6165.257    2949.496       3291      15906\n         mpg |         74     21.2973    5.785503         12         41\n       rep78 |         69    3.405797    .9899323          1          5\n    headroom |         74    2.993243    .8459948        1.5          5\n-------------+---------------------------------------------------------\n       trunk |         74    13.75676    4.277404          5         23\n      weight |         74    3019.459    777.1936       1760       4840\n      length |         74    187.9324    22.26634        142        233\n        turn |         74    39.64865    4.399354         31         51\ndisplacement |         74    197.2973    91.83722         79        425\n-------------+---------------------------------------------------------\n  gear_ratio |         74    3.014865    .4562871       2.19       3.89\n     foreign |         74    .2972973    .4601885          0          1\n\n\nif and in is to apply the command for a subset of observations, in the case of if you must specify a condition. For example we will summarize the price of those those observations with a mpg greater than its mean\n\nsu price if mpg > 21.2973\n\n(1978 Automobile Data)\n\n    Variable |        Obs        Mean    Std. Dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         31    4879.968    1344.659       3299       9735\n\n\nAs you see the number of observations and the other indicators has changed. The use of in is similar, but instead of specify a condition you must specify the position as rows number. For example get the summarize of the price for the first 20 observations\n\nsu price in 1/20\n\n(1978 Automobile Data)\n\n    Variable |        Obs        Mean    Std. Dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         20     6359.15    3710.311       3299      15906\n\n\nAlso you can see the weigth that is useful when you have weighted data, in that case you should specify a way for deal with the weights from a list of frequency weights, sampling weights, analytic weights or importance weights. To know more of this weights and its mean you should read the help documentation of weights with help weights.\nFinal element of the help documentation syntax for the command you will see [, options] and further down the documentation a table listing the options with their description. As an example in the summarize help documentation you can see the detail option and its description that says “display additional statistics” so if we use this (note the underline d)\n\nsu price, d\n\n(1978 Automobile Data)\n\n                            Price\n-------------------------------------------------------------\n      Percentiles      Smallest\n 1%         3291           3291\n 5%         3748           3299\n10%         3895           3667       Obs                  74\n25%         4195           3748       Sum of Wgt.          74\n\n50%       5006.5                      Mean           6165.257\n                        Largest       Std. Dev.      2949.496\n75%         6342          13466\n90%        11385          13594       Variance        8699526\n95%        13466          14500       Skewness       1.653434\n99%        15906          15906       Kurtosis       4.819188\n\n\nShowing how now has been displayed additional statistics as percentiles, the smallest and largest values, and others.\nUntil now we have show you the use of command, but those aren’t the only method Stata have to make some specific procedures, Stata also count with functions. Functions has a different syntax that is functioname(arguments). An example is the next\n\ndisplay sqrt(4)\n\n2\n\n\nYou must know that there are very useful commands and functions that doesn’t come along with Stata and comes with extra packages that you must download from different sources. In the next section we talk about how you can download and install those packages from one of this sources.\n\n\n\nManaging packages\nWhat are packages? Packages is a group of commands and code that develop specifics tasks. In order to install a package you have some alternatives depending on what is the package’s source, but no matter the option is the case, the procedure must be done only once in your system. Now is explained how to do it from Statistical Software Components (SSC) Archive by using the command ssc install packagename. As an example, in order to install outreg2 -that is one of the most famous Stata’s packages for arrange regression outputs into an illustrative table- you must execute the following code:\n\nssc install outreg2\n\nNow that the package is installed you doesn’t need to install it again. In Stata is enough to install once a package for use it all the times you want. Once you install it you can use it.\nThere are other sources such as the Stata Journal or simply an URL, in both cases the command net will provide the tools for search and install packages, so is highly recommendable to consult net’s help documentation.\n\n\nLoading and viewing data\nIn this section we review how to import classical data formats as csv, txt, excel and dta. For csv and txt the command is import delimited. If you see the help documentation you will see that the basic usage is:\n\nimport delimited \"Path/To/Your/File.csv\"\n\nNote that the example is made with csv but is the same for txt. If you explore the help documentation you will notice that you can specify a variety of arguments that indicates options such as the row to use as variable names, what is the separation between columns, the decimal separator and others.\nFor excel files the command is import excel. If you see the help documentation you will see that the basic usage is:\n\nimport excel \"Path/To/Your/File.xls\"\n\nNote that the example is made with xls but is the same for xlsx. If you explore the help documentation you will notice that you can specify a variety of arguments that indicates options such as if the row should be used as variable names, the range of cells, the sheet name and others.\nFinally in order to import dta files how this comes from Stata format you only need to use the command use with the basic usage as follows\n\nuse \"Path/To/Your/File.dta\"\n\nBe aware that you can import datasets from other sources such as webpages or internal repository of Stata, as was shown previously for the dataset auto.dta where was used the command sysuse.\n\n\nTyding data\nIn this section we are covering how to manipulate data, specifically how to make a simple exploratory analysis and modify the data frame. We will use the already loaded dataset auto.dta.\nAlong with this section you will see the use of the list command, this command shows us the first rows of a dataset in order, a tool that will help us to show the results of some procedures we will do.\nUntil now you know how to obtain descriptive statistics with the summarize command, now we show you how acces to that results and operate with them. One option is to do the summarize and then see the return list as follows:\n\nsu mpg\nreturn list\n\n(1978 Automobile Data)\n\n    Variable |        Obs        Mean    Std. Dev.       Min        Max\n-------------+---------------------------------------------------------\n         mpg |         74     21.2973    5.785503         12         41\n\n\nscalars:\n                  r(N) =  74\n              r(sum_w) =  74\n               r(mean) =  21.2972972972973\n                r(Var) =  33.47204738985561\n                 r(sd) =  5.785503209735141\n                r(min) =  12\n                r(max) =  41\n                r(sum) =  1576\n\n\nHere you can see that there is a group of scalars that are automatically generated by Stata once the summarize command is executed. You can freely operate with this scalars\n\ndisplay as text \"Pearson's Variation Coefficient is \" as result r(sd)/abs(r(mean))\nNA\n\n(1978 Automobile Data)\n\n    Variable |        Obs        Mean    Std. Dev.       Min        Max\n-------------+---------------------------------------------------------\n         mpg |         74     21.2973    5.785503         12         41\n\nPearson's Variation Coefficient is .27165434\n\n\nNow we show you how to create new variables with the command generate, this command allows to combine mathematical operators, functions and other variables values, among others. As an example we create the variable mpg_meandev \\[mpg_i - \\overline{mpg}\\] Where \\(\\overline{mpg}\\) is the mean of mpg variable\n\nsu mpg\ngenerate mpg_meandev = mpg - r(mean)\nlist mpg mpg_meandev in 1/5\n\n(1978 Automobile Data)\n\n    Variable |        Obs        Mean    Std. Dev.       Min        Max\n-------------+---------------------------------------------------------\n         mpg |         74     21.2973    5.785503         12         41\n\n     +-----------------+\n     | mpg   mpg_mea~v |\n     |-----------------|\n  1. |  22    .7027027 |\n  2. |  17   -4.297297 |\n  3. |  22    .7027027 |\n  4. |  20   -1.297297 |\n  5. |  15   -6.297297 |\n     +-----------------+\n\n\nAs you can see in the list output (also you can check it with browse) there is a new variable named mpg_meandev with the deviations to the mean values of mpg variable. Note that is not necessary to use de summarize command each time we want to access the return list values, we do that to visually help to see the result of the variable.\nStata also allows to replace values of this variables in the dataset, as an example we create a variable named mpg_zscore as \\[\\frac{mpg - \\overline{mpg}}{\\widehat{\\sigma}_{mpg}}\\] Where \\(\\widehat{\\sigma}_{mpg}\\) is the sample standard deviation of mpg variable. First we create this variable with missing values . and then replace this missing values with the formula\n\nsu mpg\ngenerate mpg_zscore = .\nreplace mpg_zscore = (mpg - r(mean)) / r(sd)\nlist mpg mpg_zscore in 1/5\n\n(1978 Automobile Data)\n\n    Variable |        Obs        Mean    Std. Dev.       Min        Max\n-------------+---------------------------------------------------------\n         mpg |         74     21.2973    5.785503         12         41\n\n(74 missing values generated)\n\n(74 real changes made)\n\n     +-----------------+\n     | mpg   mpg_zsc~e |\n     |-----------------|\n  1. |  22    .1214592 |\n  2. |  17   -.7427698 |\n  3. |  22    .1214592 |\n  4. |  20   -.2242324 |\n  5. |  15   -1.088462 |\n     +-----------------+\n\n\nNote that Stata also says you how many changes has done.\nOthers very useful commands are those who allows us to add more information to our dataset, this information can be more variables for each observation (merge command) or more observations for each variable (append). Another famous command for data manipulation is collapse, this command allows to create a dataset of summary statistics. As an example we calculate a series of statistics for the variable price using the by option of the command to group this summary statistics by the foreign variable.\n\ncollapse (mean) mean_price = price (sd) sd_price = price, by(foreign)\nlist\n\n(1978 Automobile Data)\n\n     +--------------------------------+\n     |  foreign   mean_p~e   sd_price |\n     |--------------------------------|\n  1. | Domestic    6,072.4    3,097.1 |\n  2. |  Foreign    6,384.7    2,621.9 |\n     +--------------------------------+\n\n\nNote that we follow the syntax\ncollapse (stat) newname = varname (stat) newname = varname ..., by(groupvariable)\nWhere the use of ... is to denote that we could add more stats to this collapse.\nNow we are going to clear all the Stata memory for latter input mannually some data for our next example:\n\nclear all\ninput str20 Zone Year Sales\n\"A\" 2021 100\n\"A\" 2022 115\n\"B\" 2021 98\n\"B\" 2022 106\nend\nlist\n\n                     Zone       Year      Sales\n  1. \"A\" 2021 100\n  2. \"A\" 2022 115\n  3. \"B\" 2021 98\n  4. \"B\" 2022 106\n  5. end\n\n     +---------------------+\n     | Zone   Year   Sales |\n     |---------------------|\n  1. |    A   2021     100 |\n  2. |    A   2022     115 |\n  3. |    B   2021      98 |\n  4. |    B   2022     106 |\n     +---------------------+\n\n\nYou could note the addition of str20 before the Zone variable name, this says to Stata that the variable Zone will be inputed as a string, if not specified Stata assumes that variables are numeric ones.\nNow we are going to show you how filter some data with the use of keep and drop, but also the use of preserve and restore. With preserve Stata internally store the actual status of the dataset and allows to make any change we want and go back to the stored status with restore. As an example first we are going to delete the variable Year with the drop command and next restore to its previous status\n\ndisplay \"This is the result before drop, is saved by preserve\"\npreserve\ndrop Year\ndisplay \"This is the result after drop\"\nlist\nrestore\ndisplay \"This is the result after restore\"\nlist\n\nRunning C:\\Users\\Usuario\\Desktop\\Prim_2023\\Ayudantias\\Investigación\\Clarke_Micr\n> oeconometriaCausalidad\\Ejemplo_QuartoBook\\profile.do . display \"This is the result before drop, is saved by preserve\"\nThis is the result before drop, is saved by preserve\n\n\n\nThis is the result after drop\n\n     +--------------+\n     | Zone   Sales |\n     |--------------|\n  1. |    A     100 |\n  2. |    A     115 |\n  3. |    B      98 |\n  4. |    B     106 |\n     +--------------+\n\n\nThis is the result after restore\n\n     +---------------------+\n     | Zone   Year   Sales |\n     |---------------------|\n  1. |    A   2021     100 |\n  2. |    A   2022     115 |\n  3. |    B   2021      98 |\n  4. |    B   2022     106 |\n     +---------------------+\n\n\nAs you can see the combination of preserve and restore allows to modify the dataset and go back, while drop remove what we specify, in the example was a variable but also can be observations in specific positions specifying in or depending on a condition specifying if. keep command works opposite to drop, as drop remove only what is specified, keep mantains only the specified and remove everything else.\nFinally in this subsection we review the reshape command that allows to transform the dataset from a wide format to a long format or backwards. Understand a long dataset as how our dataset is actually, it has multiple observations with the same value for an unit in one or more variables. In this case both zones A and B has more than one observation, one for year 2021 and one for year 2022 as you can see both observation for each zone has the same value in the variable Zone.\nIn order to transform this dataset to a wide format the code is\n\nreshape wide Sales, i(Zone) j(Year)\nlist\n\nRunning C:\\Users\\Usuario\\Desktop\\Prim_2023\\Ayudantias\\Investigación\\Clarke_Micr\n> oeconometriaCausalidad\\Ejemplo_QuartoBook\\profile.do . reshape wide Sales, i(Zone) j(Year)\n(note: j = 2021 2022)\n\nData                               long   ->   wide\n-----------------------------------------------------------------------------\nNumber of obs.                        4   ->       2\nNumber of variables                   3   ->       3\nj variable (2 values)              Year   ->   (dropped)\nxij variables:\n                                  Sales   ->   Sales2021 Sales2022\n-----------------------------------------------------------------------------\n\n     +----------------------------+\n     | Zone   Sal~2021   Sal~2022 |\n     |----------------------------|\n  1. |    A        100        115 |\n  2. |    B         98        106 |\n     +----------------------------+\n\n\nAs you can see now the dataset has one observation for each zone and no repeated values for a variable. With this we conclude this subsection and move on to the basic plots.\n\n\nBasic Plots\nThere is a variety of plots that you can create in Stata, and each plot has his own syntax, so we encourage to review the respective help documentation for each graph. In this subsection we are going to show you two basic plots: (i) line plot and (ii) scatter plot, in the latter we will review how to add a linea prediction plot.\nIn Stata the command to do a line plot is the line command, this command maps pairs of points in the \\((x,y)\\) coordinate axis and draw a line connecting this points. Let \\(x\\) be a sequence of integers between -5 and 5\n\nclear all \nset obs 11\ngenerate x = -6 + _n\n\nRunning C:\\Users\\Usuario\\Desktop\\Prim_2023\\Ayudantias\\Investigación\\Clarke_Micr\n> oeconometriaCausalidad\\Ejemplo_QuartoBook\\profile.do . clear all \n\nnumber of observations (_N) was 0, now 11\n\n\nIn this code first we clear the Stata memory, then we set the observations in the dataset to 11, with this Stata understands that there is a dataset, empty for the moment, that have 11 observations (rows). Finally it creates a variable named x that will have the value of add to -6 the row number (_n) in the dataset\n\nlist x in 1/4\n\nRunning C:\\Users\\Usuario\\Desktop\\Prim_2023\\Ayudantias\\Investigación\\Clarke_Micr\n> oeconometriaCausalidad\\Ejemplo_QuartoBook\\profile.do . list x in 1/4\n\n     +----+\n     |  x |\n     |----|\n  1. | -5 |\n  2. | -4 |\n  3. | -3 |\n  4. | -2 |\n     +----+\n\n\nNext we create \\(y = x^2\\) as follows\n\ngenerate y = x^2\n\nRunning C:\\Users\\Usuario\\Desktop\\Prim_2023\\Ayudantias\\Investigación\\Clarke_Micr\n> oeconometriaCausalidad\\Ejemplo_QuartoBook\\profile.do . generate y = x^2\n\n\nNow with line function we create the line plot\n\nline y x\n\nRunning C:\\Users\\Usuario\\Desktop\\Prim_2023\\Ayudantias\\Investigación\\Clarke_Micr\n> oeconometriaCausalidad\\Ejemplo_QuartoBook\\profile.do . line y x\n\n(file LinePlotExample.png written in PNG format)\n\n\n\n\n\nLine Plot Example\n\n\nIn the help documentation you can see a series of option that allows to modify the graph aspect. Now we show you how to graph a scatter plot, for that we are going to simulate with rnormal() 100 pseudo-random numbers from a standard normal distribution in a variable error, then in a variable x we simulate another 100 pseudo-random numbers from a standard normal distribution and finally we create \\[y_i = 10 + 3*x_i + error_i\\]\n\nclear all\nset obs 100\ngen error = rnormal()\ngen x = rnormal()\ngen y = 10 + 3*x + error\nscatter y x\n\nRunning C:\\Users\\Usuario\\Desktop\\Prim_2023\\Ayudantias\\Investigación\\Clarke_Micr\n> oeconometriaCausalidad\\Ejemplo_QuartoBook\\profile.do . clear all\n\nnumber of observations (_N) was 0, now 100\n\n\n\n\n\n(file ScatterPlotExample.png written in PNG format)\n\n\n\n\n\nScatter Plot Example\n\n\nIf you access help documentation for scatter you can see how add elements to the graph, now particularly we show how to fit a linear regression line with lfit\n\nscatter y x || lfit y x\n\nRunning C:\\Users\\Usuario\\Desktop\\Prim_2023\\Ayudantias\\Investigación\\Clarke_Micr\n> oeconometriaCausalidad\\Ejemplo_QuartoBook\\profile.do . scatter y x || lfit y x\n\n(file LfitPlotExample.png written in PNG format)\n\n\n\n\n\nLfit Plot Example\n\n\nAs said before, this introductory section of this chapter doesn’t intend to be a comprehensive tutorial of Stata, instead is a wide general guide to understand some fundamentals you will see in the rest of the chapter."
  },
  {
    "objectID": "02_02_Chapter2Stata.html",
    "href": "02_02_Chapter2Stata.html",
    "title": "Details required for Chapter 2",
    "section": "",
    "text": "Block 2.1\nTo understand the equivalence between regression analysis and the comparison of means in a binary regression set-up, we refer to Section 2.1 of the online coding resource. In this section, we work with data from a randomized control trial that examines asset transfers to poor households in India, as discussed in the paper by Banerjee et al. (2021).\n\nLoading the Data: We start by loading the household data from a specified location.\n\nuse \"C:\\\\Users\\\\maria\\\\Desktop\\\\Proyecto\\\\Data.dta\", clear\n\nSimple Regression: We run a simple regression of the variable ind_fin_el1 on the treatment variable, filtering the data to only include observations where el1 == 1.\n\nreg ind_fin_el1 treatment if el1==1\n\nWe note down the coefficient for the treatment variable for later comparison.\nMean for the Treatment Group: We calculate the mean of ind_fin_el1 for the treatment group.\n\nsummarize ind_fin_el1 if treatment==1 & el1==1\nscalar mean_treatment = r(mean)\n\nMean for the Control Group: Similarly, we calculate the mean of ind_fin_el1 for the control group.\n\nsummarize ind_fin_el1 if treatment==0 & el1==1\nscalar mean_control = r(mean)\n\nDifference in Means: We then calculate the difference in means between the treatment and control groups.\n\nscalar diff_means = mean_treatment - mean_control\ndisplay \"Difference in means (Treatment - Control): \" diff_means\n\n\nBy following these steps, we can empirically verify that in a binary regression set-up, the coefficient for the treatment variable in a simple OLS regression is equivalent to the difference in means between the treatment and control groups. This serves as a useful check for the validity of our regression model and strengthens the causal interpretation of the treatment effect."
  },
  {
    "objectID": "02_03_Chapter3Stata.html",
    "href": "02_03_Chapter3Stata.html",
    "title": "Details required for Chapter 3",
    "section": "",
    "text": "Here will be the Chapter 3 excersises and examples."
  },
  {
    "objectID": "03_00_FollowingPython.html",
    "href": "03_00_FollowingPython.html",
    "title": "Following Along with Python",
    "section": "",
    "text": "In this chapter we show you how to follow the book’s examples with Python. What is Python? Give a Python definition…\n\nipython\n\nWe recommend to work in an IDE like Spyder.\n\n\n\nSpyder screenshot\n\n\nThe rest of this chapter is organized as follow: First is shown an introduction to the language as a tutorial focused in giving the tools to following along the book’s material and procedures, next there is a series of sections focused on follow the book’s examples and make the applications in Python."
  },
  {
    "objectID": "03_01_IntroductionPython.html",
    "href": "03_01_IntroductionPython.html",
    "title": "3.1 Introduction to Python",
    "section": "",
    "text": "Here will be the introduction to Python. Now an example of code visualization:\n\nprint('Hello World!')\n\nHello World!"
  },
  {
    "objectID": "03_02_Chapter2Python.html",
    "href": "03_02_Chapter2Python.html",
    "title": "3.2 – Details required for Chapter 2",
    "section": "",
    "text": "Preliminaries\nWe will begin by examining a number of details which will be required during the exercises encountered in this chapter. This includes regression, simulation with pseudo random numbers, and some basic graphing procedures.\nTo start, we will simulate some data based on the following data generating process:\n\\(y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\\)\nwhere \\(\\beta_0=1\\), \\(\\beta_1=2\\), and both \\(x_i\\) and \\(\\varepsilon_i\\) are distributed \\(\\mathcal{N}(0,1)\\). Having conducted this simulation, we will estimate a regression model to estimate \\(\\widehat\\beta_1\\). In the book, you will be asked to consider examples which are more appropriate for the treatment effects framework which we are considering.\nFinally, we will do this 500 times, to see what the distribution of estimated paramters \\(\\widehat\\beta_1\\) looks like:\nHere we will work with data from Banerjee, Duflo, and Sharma (2021)"
  },
  {
    "objectID": "03_02_Chapter2Python.html#an-exact-p-value",
    "href": "03_02_Chapter2Python.html#an-exact-p-value",
    "title": "3.2 – Details required for Chapter 2",
    "section": "An Exact p-value",
    "text": "An Exact p-value\nIt is perhaps useful to see a simple example. Consider the case of 6 units, with 3 observations randomly assigned treatment. Imagine that the observed outcomes were then, in the treatment group: \\((34,27,29)\\), and in the control group: \\((14,18,24)\\). A simple comparison of means estimator suggests that the treatment effect is 11.33. To calculate a p-value, we can permute all the possible combinations, and ask what proportion of these are greater than or equal to this treatment effect. If we consider random orderings of 6 units, this suggests that there are \\(6!\\) possible combinations, but in reality, as we are randomly choosing 3 units from these 6 to assign a permuted treatment status, the actual value of different combinations is \\(6\\choose 3\\) \\(=\\frac{6!}{3!*(6-3)!}=20\\). We document each of these possible permutations, as well as their permuted treatment effect in the Table below. In this case, we can see that only 1 of the 20 different permutations is greater than or equal to 11.33 he original treatment status). Suggesting an exact p-value of \\(1/20=0.05\\).\n\nA Simple Illustration of Randomization Inference {.striped .hover .borderless .secondary}\n\n\nPermutation\nT1\nT2\nT3\nC1\nC2\nC3\nEstimate\n\n\n\n\nOriginal (1)\n34\n27\n29\n14\n18\n24\n11.33\n\n\n2\n34\n27\n14\n29\n18\n24\n1.33\n\n\n3\n34\n27\n18\n14\n29\n24\n4\n\n\n4\n34\n27\n24\n14\n18\n29\n8\n\n\n5\n34\n14\n29\n27\n18\n24\n2.67\n\n\n6\n34\n18\n29\n14\n27\n24\n5.33\n\n\n7\n34\n24\n29\n14\n18\n27\n9.33\n\n\n8\n14\n27\n29\n34\n18\n24\n-2\n\n\n9\n18\n27\n29\n14\n34\n24\n0.67\n\n\n10\n24\n27\n29\n14\n18\n34\n4.67\n\n\n11\n34\n14\n18\n27\n29\n24\n-4.67\n\n\n12\n34\n14\n24\n27\n18\n29\n-0.67\n\n\n13\n34\n18\n24\n14\n27\n29\n2\n\n\n14\n14\n27\n18\n34\n29\n24\n-9.33\n\n\n15\n14\n27\n24\n34\n18\n29\n-5.33\n\n\n16\n18\n27\n24\n14\n34\n29\n-2.67\n\n\n17\n14\n18\n29\n34\n27\n24\n-8\n\n\n18\n14\n24\n29\n34\n18\n27\n-4\n\n\n19\n18\n24\n29\n14\n34\n27\n-1.33\n\n\n20\n14\n18\n24\n34\n27\n29\n-11.33\n\n\n\nWe will set this up in Python. First, we will load the required libraries:\n\n#Load required libraries\nimport pandas as pd\nimport numpy as np\nfrom itertools import permutations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nWe will now enter data as a Pandas data frame, and subsequently calculate the difference in means estimator in a number of lines. You will note that in calculating the differnce in means estimator, we are first sub-setting using logical indexing (for example: data[data['W']==1], which means “choose all rows of data for which \\(W=1\\)”). Then, we calculate the means in each group using the Pandas mean() operator.\n\n#Enter data as Pandas data frame\ndata = {'Y': [34, 27, 29, 14, 18, 24],\n        'W': [1, 1, 1, 0, 0, 0]}\ndata = pd.DataFrame(data)\n\n\n#Calculate Difference in means estimator  \nY1 = data[data['W']==1]['Y']\nY0 = data[data['W']==0]['Y']\ntau = Y1.mean() - Y0.mean()\n\n\n#Generate permutations of W\nperm=permutations([1,1,1,0,0,0])\n#Wperm=perm\nWperm = set(perm)\n\nTaus = []\nfor p in Wperm:\n    dataP = pd.DataFrame({'Y': [34, 27, 29, 14, 18, 24], 'W': p})\n    tauP = dataP[dataP['W']==1]['Y'].mean()-dataP[dataP['W']==0]['Y'].mean()\n    Taus.append(tauP)\n\n\np_2side = sum(np.absolute(Taus)>=tau)/len(Taus)\np_1side = sum(Taus>=tau)/len(Taus)\n\nprint(\"The two-sided p-value is: \" + str(p_2side))\n\nThe two-sided p-value is: 0.1\n\n\n\n#Generate graph\nsns.set_palette(\"pastel\")\nplt.hist(Taus,bins=10, edgecolor='black', density=True, label=\"Permutations\")\nplt.ylabel(\"Density\")\nplt.xlabel(\"Test statistic\")\nplt.axvline(tau, color='red', linestyle='dashed', label=r'$\\widehat\\tau$')\nplt.legend() \nplt.show()\n\n\n\n\nFigure 13.1: Permutation inference"
  },
  {
    "objectID": "03_02_Chapter2Python.html#randomization-inference-with-a-larger-dataset",
    "href": "03_02_Chapter2Python.html#randomization-inference-with-a-larger-dataset",
    "title": "3.2 – Details required for Chapter 2",
    "section": "Randomization inference with a larger dataset",
    "text": "Randomization inference with a larger dataset\nHere we will return to the example from Banerjee, Duflo, and Sharma (2021).\n\nPreserve the original treatment assignment.\nGenerate placebo treatment statuses according to the original assignment method.\nEstimate the original regression equation with an additional term for the placebo treatment.\nRepeat #1–3.\nThe randomization inference p-value is the proportion of times the placebo treatment effect was larger than the estimated treatment effect.\n\n\n\n\n\nBanerjee, Abhijit, Esther Duflo, and Garima Sharma. 2021. “Long-Term Effects of the Targeting the Ultra Poor Program.” American Economic Review: Insights 3 (4): 471–86. https://doi.org/10.1257/aeri.20200667."
  },
  {
    "objectID": "03_03_Chapter3Python.html",
    "href": "03_03_Chapter3Python.html",
    "title": "Details required for Chapter 3",
    "section": "",
    "text": "Here will be the Chapter 3 excersises and examples."
  }
]